% $ biblatex auxiliary file $
% $ biblatex bbl format version 2.9 $
% Do not modify the above lines!
%
% This is an auxiliary file used by the 'biblatex' package.
% This file may safely be deleted. It will be recreated by
% biber as required.
%
\begingroup
\makeatletter
\@ifundefined{ver@biblatex.sty}
  {\@latex@error
     {Missing 'biblatex' package}
     {The bibliography requires the 'biblatex' package.}
      \aftergroup\endinput}
  {}
\endgroup


\refsection{0}
  \datalist[entry]{none/global//global/global}
    \entry{2003_Barla_CONF}{inproceedings}{}
      \name{author}{3}{}{%
        {{hash=0a14a321ba454be3d281da0137474901}{%
           family={Barla},
           familyi={B\bibinitperiod},
           given={A.},
           giveni={A\bibinitperiod}}}%
        {{hash=6048020885aa0beb534f65a5ec8892ea}{%
           family={Odone},
           familyi={O\bibinitperiod},
           given={F.},
           giveni={F\bibinitperiod}}}%
        {{hash=6ca2a2b7a4ab1b1975188c12c7ae042a}{%
           family={Verri},
           familyi={V\bibinitperiod},
           given={A.},
           giveni={A\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {IEEE}%
      }
      \strng{namehash}{c6d53442e756301ef232ec81c57bd23d}
      \strng{fullhash}{c6d53442e756301ef232ec81c57bd23d}
      \strng{bibnamehash}{c6d53442e756301ef232ec81c57bd23d}
      \strng{authorbibnamehash}{c6d53442e756301ef232ec81c57bd23d}
      \strng{authornamehash}{c6d53442e756301ef232ec81c57bd23d}
      \strng{authorfullhash}{c6d53442e756301ef232ec81c57bd23d}
      \field{sortinit}{1}
      \field{sortinithash}{2174f786c6195e7fe2ee1c229b416e29}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In this paper we address the problem of classifying images, by exploiting global features that describe color and illumination properties, and by using the statistical learning paradigm. The contribution of this paper is twofold. First, we show that histogram intersection has the required mathematical properties to be used as a kernel function for support vector machines (SVMs). Second, we give two examples of how a SVM, equipped with such a kernel, can achieve very promising results on image classification based on color information.}
      \field{booktitle}{Proceedings 2003 International Conference on Image Processing (Cat. No.03CH37429)}
      \field{title}{Histogram intersection kernel for image classification}
      \field{year}{2003}
      \verb{doi}
      \verb 10.1109/icip.2003.1247294
      \endverb
    \endentry
    \entry{2005_Boughorbel_IEEE}{inproceedings}{}
      \name{author}{3}{}{%
        {{hash=63c4ddaabf6de299de9d70546894fe14}{%
           family={Boughorbel},
           familyi={B\bibinitperiod},
           given={S.},
           giveni={S\bibinitperiod}}}%
        {{hash=171ad98c75268f6d25fb8743d4ccec3a}{%
           family={Tarel},
           familyi={T\bibinitperiod},
           given={J.-P.},
           giveni={J\bibinithyphendelim P\bibinitperiod}}}%
        {{hash=52685368f3601cec7566cca49ace5fc4}{%
           family={Boujemaa},
           familyi={B\bibinitperiod},
           given={N.},
           giveni={N\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {IEEE}%
      }
      \strng{namehash}{46aef6053d277271de93edd8841c4ec5}
      \strng{fullhash}{46aef6053d277271de93edd8841c4ec5}
      \strng{bibnamehash}{46aef6053d277271de93edd8841c4ec5}
      \strng{authorbibnamehash}{46aef6053d277271de93edd8841c4ec5}
      \strng{authornamehash}{46aef6053d277271de93edd8841c4ec5}
      \strng{authorfullhash}{46aef6053d277271de93edd8841c4ec5}
      \field{sortinit}{1}
      \field{sortinithash}{2174f786c6195e7fe2ee1c229b416e29}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Histogram intersection (HI) kernel has been recently introduced for image recognition tasks. The HI kernel is proved to be positive definite and thus can be used in support vector machine (SVM) based recognition. Experimentally, it also leads to good recognition performances. However, its derivation applies only for binary strings such as color histograms computed on equally sized images. In this paper, we propose a new kernel, which we named generalized histogram intersection (GHI) kernel, since it applies in a much larger variety of contexts. First, an original derivation of the positive definiteness of the GHI kernel is proposed in the general case. As a consequence, vectors of real values can be used, and the images no longer need to have the same size. Second, a hyper-parameter is added, compared to the HI kernel, which allows us to better tune the kernel model to particular databases. We present experiments which prove that the GHI kernel outperforms the simple HI kernel in a simple recognition task. Comparisons with other well-known kernels are also provided.}
      \field{booktitle}{{IEEE} International Conference on Image Processing 2005}
      \field{title}{Generalized histogram intersection kernel for image recognition}
      \field{year}{2005}
      \verb{doi}
      \verb 10.1109/icip.2005.1530353
      \endverb
    \endentry
    \entry{2007_Grauman_CONF}{article}{}
      \name{author}{2}{}{%
        {{hash=f67e08fa64fd602c4ec562da14d65216}{%
           family={Grauman},
           familyi={G\bibinitperiod},
           given={Kristen},
           giveni={K\bibinitperiod}}}%
        {{hash=90180e1a30742e0d15328bfe637c2ef4}{%
           family={Darrell},
           familyi={D\bibinitperiod},
           given={Trevor},
           giveni={T\bibinitperiod}}}%
      }
      \strng{namehash}{8c6218cef53ea82a71c568bdcd1c904c}
      \strng{fullhash}{8c6218cef53ea82a71c568bdcd1c904c}
      \strng{bibnamehash}{8c6218cef53ea82a71c568bdcd1c904c}
      \strng{authorbibnamehash}{8c6218cef53ea82a71c568bdcd1c904c}
      \strng{authornamehash}{8c6218cef53ea82a71c568bdcd1c904c}
      \strng{authorfullhash}{8c6218cef53ea82a71c568bdcd1c904c}
      \field{sortinit}{1}
      \field{sortinithash}{2174f786c6195e7fe2ee1c229b416e29}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{Journal of Machine Learning Research}
      \field{number}{4}
      \field{title}{The pyramid match kernel: Efficient learning with sets of features.}
      \field{volume}{8}
      \field{year}{2007}
    \endentry
    \entry{2007_Harchaoui_IEEE}{inproceedings}{}
      \name{author}{2}{}{%
        {{hash=93f7c37f41abcababec1f53b76184ef8}{%
           family={Harchaoui},
           familyi={H\bibinitperiod},
           given={Zaid},
           giveni={Z\bibinitperiod}}}%
        {{hash=93da2819ab01d8a5e7bae39ce6f17c1f}{%
           family={Bach},
           familyi={B\bibinitperiod},
           given={Francis},
           giveni={F\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {IEEE}%
      }
      \strng{namehash}{9e8eb6fd7eeb1f5988d7c4b1c5e8ece7}
      \strng{fullhash}{9e8eb6fd7eeb1f5988d7c4b1c5e8ece7}
      \strng{bibnamehash}{9e8eb6fd7eeb1f5988d7c4b1c5e8ece7}
      \strng{authorbibnamehash}{9e8eb6fd7eeb1f5988d7c4b1c5e8ece7}
      \strng{authornamehash}{9e8eb6fd7eeb1f5988d7c4b1c5e8ece7}
      \strng{authorfullhash}{9e8eb6fd7eeb1f5988d7c4b1c5e8ece7}
      \field{sortinit}{1}
      \field{sortinithash}{2174f786c6195e7fe2ee1c229b416e29}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We propose a family of kernels between images, defined as kernels between their respective segmentation graphs. The kernels are based on soft matching of subtree-patterns of the respective graphs, leveraging the natural structure of images while remaining robust to the associated segmentation process uncertainty. Indeed, output from morphological segmentation is often represented by a labelled graph, each vertex corresponding to a segmented region, with edges joining neighboring regions. However, such image representations have mostly remained underused for learning tasks, partly because of the observed instability of the segmentation process and the inherent hardness of inexact graph matching with uncertain graphs. Our kernels count common virtual substructures amongst images, which enables to perform efficient supervised classification of natural images with a support vector machine. Moreover, the kernel machinery allows us to take advantage of recent advances in kernel-based learning: (i) semi-supervised learning reduces the required number of labelled images, while (ii) multiple kernel learning algorithms efficiently select the most relevant similarity measures between images within our family.}
      \field{booktitle}{2007 {IEEE} Conference on Computer Vision and Pattern Recognition}
      \field{month}{6}
      \field{title}{Image Classification with Segmentation Graph Kernels}
      \field{year}{2007}
      \verb{doi}
      \verb 10.1109/cvpr.2007.383049
      \endverb
      \verb{file}
      \verb :/home/fabrice/Documents/Uni/Literature/Papers/2007_Harchaoui_IEEE.pdf:PDF
      \endverb
      \verb{urlraw}
      \verb https://www.researchgate.net/publication/4260036_Image_Classification_with_Segmentation_Graph_Kernels
      \endverb
      \verb{url}
      \verb https://www.researchgate.net/publication/4260036_Image_Classification_with_Segmentation_Graph_Kernels
      \endverb
    \endentry
    \entry{1999_Manning_CONF}{book}{}
      \name{author}{2}{}{%
        {{hash=ff4377244c68b8beb3253e53d6387f94}{%
           family={Manning},
           familyi={M\bibinitperiod},
           given={Christopher},
           giveni={C\bibinitperiod}}}%
        {{hash=8cb60a2762886ba947dbb244a0cfebde}{%
           family={Schutze},
           familyi={S\bibinitperiod},
           given={Hinrich},
           giveni={H\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {MIT press}%
      }
      \strng{namehash}{dbe7efc6cca2ac638f0ce1e74827c205}
      \strng{fullhash}{dbe7efc6cca2ac638f0ce1e74827c205}
      \strng{bibnamehash}{dbe7efc6cca2ac638f0ce1e74827c205}
      \strng{authorbibnamehash}{dbe7efc6cca2ac638f0ce1e74827c205}
      \strng{authornamehash}{dbe7efc6cca2ac638f0ce1e74827c205}
      \strng{authorfullhash}{dbe7efc6cca2ac638f0ce1e74827c205}
      \field{sortinit}{2}
      \field{sortinithash}{cbff857e587bcb4635511624d773949e}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{title}{Foundations of statistical natural language processing}
      \field{year}{1999}
    \endentry
    \entry{2000_Abiteboul_CONF}{book}{}
      \name{author}{3}{}{%
        {{hash=e99985780977196e6a1237ff2144092e}{%
           family={Abiteboul},
           familyi={A\bibinitperiod},
           given={Serge},
           giveni={S\bibinitperiod}}}%
        {{hash=0e2b444d9d3a80f70ca5eb50e7596a60}{%
           family={Buneman},
           familyi={B\bibinitperiod},
           given={Peter},
           giveni={P\bibinitperiod}}}%
        {{hash=dad05536948804793c3e454acd5ecb8f}{%
           family={Suciu},
           familyi={S\bibinitperiod},
           given={Dan},
           giveni={D\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Morgan Kaufmann}%
      }
      \strng{namehash}{616c7bbfeab53a60df30c7f0b59f9b43}
      \strng{fullhash}{616c7bbfeab53a60df30c7f0b59f9b43}
      \strng{bibnamehash}{616c7bbfeab53a60df30c7f0b59f9b43}
      \strng{authorbibnamehash}{616c7bbfeab53a60df30c7f0b59f9b43}
      \strng{authornamehash}{616c7bbfeab53a60df30c7f0b59f9b43}
      \strng{authorfullhash}{616c7bbfeab53a60df30c7f0b59f9b43}
      \field{sortinit}{3}
      \field{sortinithash}{a4b52e5432884761f50fb9571273b93e}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{title}{Data on the web: from relations to semistructured data and {XML}}
      \field{year}{2000}
    \endentry
    \entry{2015_Bai_CONF}{inproceedings}{}
      \name{author}{4}{}{%
        {{hash=aae746328c8ba1574a36be2c133659f2}{%
           family={Bai},
           familyi={B\bibinitperiod},
           given={Lu},
           giveni={L\bibinitperiod}}}%
        {{hash=d1c3d318e9e1f80f90b5f52bfe7c2186}{%
           family={Rossi},
           familyi={R\bibinitperiod},
           given={Luca},
           giveni={L\bibinitperiod}}}%
        {{hash=f6862918de72ae33b5ff43ff16164254}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Zhihong},
           giveni={Z\bibinitperiod}}}%
        {{hash=3fcfa549c90d93643a12e72c1f264a33}{%
           family={Hancock},
           familyi={H\bibinitperiod},
           given={Edwin},
           giveni={E\bibinitperiod}}}%
      }
      \name{editor}{2}{}{%
        {{hash=93da2819ab01d8a5e7bae39ce6f17c1f}{%
           family={Bach},
           familyi={B\bibinitperiod},
           given={Francis},
           giveni={F\bibinitperiod}}}%
        {{hash=df034c01f40f9863f7986f0670e3f863}{%
           family={Blei},
           familyi={B\bibinitperiod},
           given={David},
           giveni={D\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Lille, France}%
      }
      \list{publisher}{1}{%
        {PMLR}%
      }
      \strng{namehash}{39ae3a1735850d8d3ada37450e617ede}
      \strng{fullhash}{e3a4bb0bb254793e68b3e49f54c08025}
      \strng{bibnamehash}{39ae3a1735850d8d3ada37450e617ede}
      \strng{authorbibnamehash}{39ae3a1735850d8d3ada37450e617ede}
      \strng{authornamehash}{39ae3a1735850d8d3ada37450e617ede}
      \strng{authorfullhash}{e3a4bb0bb254793e68b3e49f54c08025}
      \strng{editorbibnamehash}{4188f673e8c288b53fdbccdd66b77f3f}
      \strng{editornamehash}{4188f673e8c288b53fdbccdd66b77f3f}
      \strng{editorfullhash}{4188f673e8c288b53fdbccdd66b77f3f}
      \field{sortinit}{4}
      \field{sortinithash}{11cdaee3b18e01d77f3f428b13c1fc76}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In this paper, we develop a new entropic matching kernel for weighted graphs by aligning depth-based representations. We demonstrate that this kernel can be seen as an \textbfaligned subtree kernel that incorporates explicit subtree correspondences, and thus addresses the drawback of neglecting the relative locations between substructures that arises in the R-convolution kernels. Experiments on standard datasets demonstrate that our kernel can easily outperform state-of-the-art graph kernels in terms of classification accuracy.}
      \field{booktitle}{Proceedings of the 32nd International Conference on Machine Learning}
      \field{month}{7}
      \field{series}{Proceedings of Machine Learning Research}
      \field{title}{An Aligned Subtree Kernel for Weighted Graphs}
      \field{volume}{37}
      \field{year}{2015}
      \field{pages}{30\bibrangedash 39}
      \range{pages}{10}
      \verb{file}
      \verb http://proceedings.mlr.press/v37/bai15.pdf
      \endverb
      \verb{urlraw}
      \verb https://proceedings.mlr.press/v37/bai15.html
      \endverb
      \verb{url}
      \verb https://proceedings.mlr.press/v37/bai15.html
      \endverb
    \endentry
    \entry{2005_Borgwardt_CONF}{article}{}
      \name{author}{6}{}{%
        {{hash=484439e72626bfa85c56dd5f2b653199}{%
           family={Borgwardt},
           familyi={B\bibinitperiod},
           given={K.\bibnamedelimi M.},
           giveni={K\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
        {{hash=69a6da865bd1dc6c1df4467b0fa65593}{%
           family={Ong},
           familyi={O\bibinitperiod},
           given={C.\bibnamedelimi S.},
           giveni={C\bibinitperiod\bibinitdelim S\bibinitperiod}}}%
        {{hash=73599401dd0cb7b86fecc7a69e14fdc8}{%
           family={Schonauer},
           familyi={S\bibinitperiod},
           given={S.},
           giveni={S\bibinitperiod}}}%
        {{hash=e8b108a34672d11328ea389ebc612976}{%
           family={Vishwanathan},
           familyi={V\bibinitperiod},
           given={S.\bibnamedelimi V.\bibnamedelimi N.},
           giveni={S\bibinitperiod\bibinitdelim V\bibinitperiod\bibinitdelim N\bibinitperiod}}}%
        {{hash=1aafc45c3e691d23a4875d34eb2a5d7c}{%
           family={Smola},
           familyi={S\bibinitperiod},
           given={A.\bibnamedelimi J.},
           giveni={A\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
        {{hash=f480ff76f70ded04c2f2a037f2f56876}{%
           family={Kriegel},
           familyi={K\bibinitperiod},
           given={H.-P.},
           giveni={H\bibinithyphendelim P\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Oxford University Press ({OUP})}%
      }
      \strng{namehash}{78e3046ad07e27cdb85887f14bd20eaf}
      \strng{fullhash}{db228681cb54e2a1418abacd598263c9}
      \strng{bibnamehash}{78e3046ad07e27cdb85887f14bd20eaf}
      \strng{authorbibnamehash}{78e3046ad07e27cdb85887f14bd20eaf}
      \strng{authornamehash}{78e3046ad07e27cdb85887f14bd20eaf}
      \strng{authorfullhash}{db228681cb54e2a1418abacd598263c9}
      \field{sortinit}{5}
      \field{sortinithash}{3c19c3776b658b3558e9e2e4840c01e2}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{Bioinformatics}
      \field{month}{6}
      \field{number}{Suppl 1}
      \field{title}{Protein function prediction via graph kernels}
      \field{volume}{21}
      \field{year}{2005}
      \field{pages}{i47\bibrangedash i56}
      \range{pages}{-1}
      \verb{doi}
      \verb 10.1093/bioinformatics/bti1007
      \endverb
      \verb{urlraw}
      \verb https://academic.oup.com/bioinformatics/article/21/suppl_1/i47/202991?login=true
      \endverb
      \verb{url}
      \verb https://academic.oup.com/bioinformatics/article/21/suppl_1/i47/202991?login=true
      \endverb
    \endentry
    \entry{2005_Froehlich_ICML}{inproceedings}{}
      \name{author}{4}{}{%
        {{hash=4e2d5d096be70bac495c26a9f5e778e2}{%
           family={Fröhlich},
           familyi={F\bibinitperiod},
           given={Holger},
           giveni={H\bibinitperiod}}}%
        {{hash=69b07d37651f188246c8dfd3b45d8306}{%
           family={Wegner},
           familyi={W\bibinitperiod},
           given={Jörg\bibnamedelima K.},
           giveni={J\bibinitperiod\bibinitdelim K\bibinitperiod}}}%
        {{hash=e9432331c985ebde18de677f58c4a3eb}{%
           family={Sieker},
           familyi={S\bibinitperiod},
           given={Florian},
           giveni={F\bibinitperiod}}}%
        {{hash=650741453181162d551d5db838d0856f}{%
           family={Zell},
           familyi={Z\bibinitperiod},
           given={Andreas},
           giveni={A\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {{ACM} Press}%
      }
      \strng{namehash}{a65e1c9d445e0b2f8600bad872ba7e95}
      \strng{fullhash}{55b64a6a854435ebf1b2db3ec8c01252}
      \strng{bibnamehash}{a65e1c9d445e0b2f8600bad872ba7e95}
      \strng{authorbibnamehash}{a65e1c9d445e0b2f8600bad872ba7e95}
      \strng{authornamehash}{a65e1c9d445e0b2f8600bad872ba7e95}
      \strng{authorfullhash}{55b64a6a854435ebf1b2db3ec8c01252}
      \field{sortinit}{5}
      \field{sortinithash}{3c19c3776b658b3558e9e2e4840c01e2}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We propose a new kernel function for attributed molecular graphs, which is based on the idea of computing an optimal assignment from the atoms of one molecule to those of another one, including information on neighborhood, membership to a certain structural element and other characteristics for each atom. As a byproduct this leads to a new class of kernel functions. We demonstrate how the necessary computations can be carried out efficiently. Compared to marginalized graph kernels our method in some cases leads to a significant reduction of the prediction error. Further improvement can be gained, if expert knowledge is combined with our method. We also investigate a reduced graph representation of molecules by collapsing certain structural elements, like e.g. rings, into a single node of the molecular graph.}
      \field{booktitle}{Proceedings of the 22nd international conference on Machine learning - {ICML} {'}05}
      \field{title}{Optimal assignment kernels for attributed molecular graphs}
      \field{year}{2005}
      \verb{doi}
      \verb 10.1145/1102351.1102380
      \endverb
    \endentry
    \entry{2011_Shervashidze_JMLR}{article}{}
      \name{author}{5}{}{%
        {{hash=23497b31a021c2543718505ff30158c5}{%
           family={Shervashidze},
           familyi={S\bibinitperiod},
           given={Nino},
           giveni={N\bibinitperiod}}}%
        {{hash=7716daa9abe2da8fb7fcf652e434a9e9}{%
           family={Schweitzer},
           familyi={S\bibinitperiod},
           given={Pascal},
           giveni={P\bibinitperiod}}}%
        {{hash=11a2a4714831d916d95fef24df4421af}{%
           family={Leeuwen},
           familyi={L\bibinitperiod},
           given={Erik\bibnamedelima Jan},
           giveni={E\bibinitperiod\bibinitdelim J\bibinitperiod},
           prefix={van},
           prefixi={v\bibinitperiod}}}%
        {{hash=c2f239e3cf9c48b72ce5f4ca9b5e478e}{%
           family={Mehlhorn},
           familyi={M\bibinitperiod},
           given={Kurt},
           giveni={K\bibinitperiod}}}%
        {{hash=67b59c2b88bd10672a789826aedb1e91}{%
           family={Borgwardt},
           familyi={B\bibinitperiod},
           given={Karsten\bibnamedelima M.},
           giveni={K\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
      }
      \strng{namehash}{f179debd3033b55b2559b8d784cf59c7}
      \strng{fullhash}{94e0e3e166eb8522540115872873399f}
      \strng{bibnamehash}{f179debd3033b55b2559b8d784cf59c7}
      \strng{authorbibnamehash}{f179debd3033b55b2559b8d784cf59c7}
      \strng{authornamehash}{f179debd3033b55b2559b8d784cf59c7}
      \strng{authorfullhash}{94e0e3e166eb8522540115872873399f}
      \field{sortinit}{5}
      \field{sortinithash}{3c19c3776b658b3558e9e2e4840c01e2}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In this article, we propose a family of efficient kernels for large graphs with discrete node labels. Key to our method is a rapid feature extraction scheme based on the Weisfeiler-Lehman test of isomorphism on graphs. It maps the original graph to a sequence of graphs, whose node attributes capture topological and label information. A family of kernels can be defined based on this Weisfeiler-Lehman sequence of graphs, including a highly efficient kernel comparing subtree-like patterns. Its runtime scales only linearly in the number of edges of the graphs and the length of the Weisfeiler-Lehman graph sequence. In our experimental evaluation, our kernels outperform state-of-the-art graph kernels on several graph classification benchmark data sets in terms of accuracy and runtime. Our kernels open the door to large-scale applications of graph kernels in various disciplines such as computational biology and social network analysis.}
      \field{journaltitle}{J. Mach. Learn. Res.}
      \field{title}{Weisfeiler-Lehman Graph and Kernels}
      \field{volume}{12}
      \field{year}{2011}
      \field{pages}{2539\bibrangedash 2561}
      \range{pages}{23}
      \verb{file}
      \verb :/home/fabrice/Documents/Uni/Literature/Papers/2011_Shervashidze_JMLR.pdf:PDF
      \endverb
      \verb{urlraw}
      \verb http://dl.acm.org/citation.cfm?id=2078187
      \endverb
      \verb{url}
      \verb http://dl.acm.org/citation.cfm?id=2078187
      \endverb
      \keyw{graph kernels,graph classification,similarity measures for graphs,Weisfeiler-Lehman algorithm}
    \endentry
    \entry{1991_Debnath_CONF}{article}{}
      \name{author}{5}{}{%
        {{hash=38b49017c38801a472b5d8c634502139}{%
           family={Debnath},
           familyi={D\bibinitperiod},
           given={Asim\bibnamedelima Kumar},
           giveni={A\bibinitperiod\bibinitdelim K\bibinitperiod}}}%
        {{hash=35e516ea09f81c2cbb57a51cce1b206f}{%
           family={Compadre},
           familyi={C\bibinitperiod},
           given={Rosa\bibnamedelimb L.\bibnamedelimi Lopez},
           giveni={R\bibinitperiod\bibinitdelim L\bibinitperiod\bibinitdelim L\bibinitperiod},
           prefix={de},
           prefixi={d\bibinitperiod}}}%
        {{hash=6ebfaa65ca715298a98406f3851e7718}{%
           family={Debnath},
           familyi={D\bibinitperiod},
           given={Gargi},
           giveni={G\bibinitperiod}}}%
        {{hash=149771794b3ad6cbd67a7e64f7ef6906}{%
           family={Shusterman},
           familyi={S\bibinitperiod},
           given={Alan\bibnamedelima J.},
           giveni={A\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
        {{hash=12b7fb42e12959db15f687c93cb7bb46}{%
           family={Hansch},
           familyi={H\bibinitperiod},
           given={Corwin},
           giveni={C\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {American Chemical Society ({ACS})}%
      }
      \strng{namehash}{84d25321241cc4bf1f581bc9984d55d6}
      \strng{fullhash}{0b45220997a66c07e4f77c0d21b0f758}
      \strng{bibnamehash}{84d25321241cc4bf1f581bc9984d55d6}
      \strng{authorbibnamehash}{84d25321241cc4bf1f581bc9984d55d6}
      \strng{authornamehash}{84d25321241cc4bf1f581bc9984d55d6}
      \strng{authorfullhash}{0b45220997a66c07e4f77c0d21b0f758}
      \field{sortinit}{6}
      \field{sortinithash}{57e57fb8451e7fcfa45d1e069f6d3136}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{Journal of Medicinal Chemistry}
      \field{month}{2}
      \field{number}{2}
      \field{title}{Structure-activity relationship of mutagenic aromatic and heteroaromatic nitro compounds. Correlation with molecular orbital energies and hydrophobicity}
      \field{volume}{34}
      \field{year}{1991}
      \field{pages}{786\bibrangedash 797}
      \range{pages}{12}
      \verb{doi}
      \verb 10.1021/jm00106a046
      \endverb
      \verb{file}
      \verb :1991_Debnath_CONF - Structure Activity Relationship of Mutagenic Aromatic and Heteroaromatic Nitro Compounds. Correlation with Molecular Orbital Energies and Hydrophobicity.pdf:PDF
      \endverb
      \verb{urlraw}
      \verb https://pubs.acs.org/doi/10.1021/jm00106a046
      \endverb
      \verb{url}
      \verb https://pubs.acs.org/doi/10.1021/jm00106a046
      \endverb
    \endentry
    \entry{1979_Garey_BOOK}{book}{}
      \name{author}{2}{}{%
        {{hash=4b59afd552bf787d8ca7794b6863cb9c}{%
           family={Garey},
           familyi={G\bibinitperiod},
           given={M.\bibnamedelimi R.},
           giveni={M\bibinitperiod\bibinitdelim R\bibinitperiod}}}%
        {{hash=8c7f2a207a19e41869867861822a3f38}{%
           family={Johnson},
           familyi={J\bibinitperiod},
           given={D.\bibnamedelimi S.},
           giveni={D\bibinitperiod\bibinitdelim S\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {W. H. Freeman {\&} Co.}%
      }
      \strng{namehash}{e54b2ca70becb7127281d2472e81186f}
      \strng{fullhash}{e54b2ca70becb7127281d2472e81186f}
      \strng{bibnamehash}{e54b2ca70becb7127281d2472e81186f}
      \strng{authorbibnamehash}{e54b2ca70becb7127281d2472e81186f}
      \strng{authornamehash}{e54b2ca70becb7127281d2472e81186f}
      \strng{authorfullhash}{e54b2ca70becb7127281d2472e81186f}
      \field{sortinit}{8}
      \field{sortinithash}{07edf88d4ea82509b9c4b4d13f41c452}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{isbn}{0716710455}
      \field{month}{1}
      \field{pagetotal}{340}
      \field{title}{Computers and Intractability: A Guide to the Theory of {NP}-Completeness}
      \field{year}{1979}
      \verb{urlraw}
      \verb https://www.ebook.de/de/product/3637119/m_r_garey_d_s_johnson_computers_and_intractability_a_guide_to_the_theory_of_np_completeness.html
      \endverb
      \verb{url}
      \verb https://www.ebook.de/de/product/3637119/m_r_garey_d_s_johnson_computers_and_intractability_a_guide_to_the_theory_of_np_completeness.html
      \endverb
    \endentry
    \entry{1977_Read_CONF}{article}{}
      \name{author}{2}{}{%
        {{hash=ce5815b2dcdc6235fd83ef5d05bc7ccb}{%
           family={Read},
           familyi={R\bibinitperiod},
           given={Ronald\bibnamedelima C.},
           giveni={R\bibinitperiod\bibinitdelim C\bibinitperiod}}}%
        {{hash=2d18ec9f6ba654018e1bace415092ea7}{%
           family={Corneil},
           familyi={C\bibinitperiod},
           given={Derek\bibnamedelima G.},
           giveni={D\bibinitperiod\bibinitdelim G\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Wiley}%
      }
      \strng{namehash}{109583b6537fdda01c4e5b0772a46ea2}
      \strng{fullhash}{109583b6537fdda01c4e5b0772a46ea2}
      \strng{bibnamehash}{109583b6537fdda01c4e5b0772a46ea2}
      \strng{authorbibnamehash}{109583b6537fdda01c4e5b0772a46ea2}
      \strng{authornamehash}{109583b6537fdda01c4e5b0772a46ea2}
      \strng{authorfullhash}{109583b6537fdda01c4e5b0772a46ea2}
      \field{sortinit}{9}
      \field{sortinithash}{1dd72ab054147731c9d824b49aba0534}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{The graph isomorphism problem—to devise a good algorithm for determining if two graphs are isomorphic—is of considerable practical importance, and is also of theoretical interest due to its relationship to the concept of NP-completeness. No efficient (i.e., polynomial-bound) algorithm for graph isomorphism is known, and it has been conjectured that no such algorithm can exist. Many papers on the subject have appeared, but progress has been slight; in fact, the intractable nature of the problem and the way that many graph theorists have been led to devote much time to it, recall those aspects of the four-color conjecture which prompted Harary to rechristen it the “four-color disease.” This paper surveys the present state of the art of isomorphism testing, discusses its relationship to NP-completeness, and indicates some of the difficulties inherent in this particularly elusive and challenging problem. A comprehensive bibliography of papers relating to the graph isomorphism problem is given.}
      \field{journaltitle}{Journal of Graph Theory}
      \field{number}{4}
      \field{title}{The graph isomorphism disease}
      \field{volume}{1}
      \field{year}{1977}
      \field{pages}{339\bibrangedash 363}
      \range{pages}{25}
      \verb{doi}
      \verb 10.1002/jgt.3190010410
      \endverb
    \endentry
    \entry{1983_Bunke_ELSEVIER}{article}{}
      \name{author}{2}{}{%
        {{hash=70bcbe1cf010b2edb3370eff6b21f444}{%
           family={Bunke},
           familyi={B\bibinitperiod},
           given={H.},
           giveni={H\bibinitperiod}}}%
        {{hash=235e1d3cb7676e90fbf5123c21ddfd21}{%
           family={Allermann},
           familyi={A\bibinitperiod},
           given={G.},
           giveni={G\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Elsevier {BV}}%
      }
      \strng{namehash}{ebe97a3980a5a5d674f1be485c4315aa}
      \strng{fullhash}{ebe97a3980a5a5d674f1be485c4315aa}
      \strng{bibnamehash}{ebe97a3980a5a5d674f1be485c4315aa}
      \strng{authorbibnamehash}{ebe97a3980a5a5d674f1be485c4315aa}
      \strng{authornamehash}{ebe97a3980a5a5d674f1be485c4315aa}
      \strng{authorfullhash}{ebe97a3980a5a5d674f1be485c4315aa}
      \field{sortinit}{1}
      \field{sortinithash}{2174f786c6195e7fe2ee1c229b416e29}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{Pattern Recognition Letters}
      \field{month}{3}
      \field{number}{4}
      \field{title}{Inexact graph matching for structural pattern recognition}
      \field{volume}{1}
      \field{year}{1983}
      \field{pages}{245\bibrangedash 253}
      \range{pages}{9}
      \verb{doi}
      \verb 10.1016/0167-8655(83)90033-8
      \endverb
    \endentry
    \entry{2008_Kondor_ICML}{inproceedings}{}
      \name{author}{2}{}{%
        {{hash=6abc8eb3beac1cdef82d485e69f760df}{%
           family={Kondor},
           familyi={K\bibinitperiod},
           given={Risi},
           giveni={R\bibinitperiod}}}%
        {{hash=67b59c2b88bd10672a789826aedb1e91}{%
           family={Borgwardt},
           familyi={B\bibinitperiod},
           given={Karsten\bibnamedelima M.},
           giveni={K\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {{ACM} Press}%
      }
      \strng{namehash}{95eac742e5e991463ca2158135c05165}
      \strng{fullhash}{95eac742e5e991463ca2158135c05165}
      \strng{bibnamehash}{95eac742e5e991463ca2158135c05165}
      \strng{authorbibnamehash}{95eac742e5e991463ca2158135c05165}
      \strng{authornamehash}{95eac742e5e991463ca2158135c05165}
      \strng{authorfullhash}{95eac742e5e991463ca2158135c05165}
      \field{sortinit}{1}
      \field{sortinithash}{2174f786c6195e7fe2ee1c229b416e29}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{Proceedings of the 25th international conference on Machine learning - {ICML} {'}08}
      \field{title}{The skew spectrum of graphs}
      \field{year}{2008}
      \verb{doi}
      \verb 10.1145/1390156.1390219
      \endverb
      \verb{file}
      \verb :/home/fabrice/Documents/Uni/Literature/Papers/2009_Kondor_ICML.pdf:PDF
      \endverb
      \verb{urlraw}
      \verb https://dl.acm.org/doi/abs/10.1145/1390156.1390219?casa_token=ThkykpcwxJMAAAAA:m3YTBBF3m4J6caTUcl-CfITmu45s9R7G9BG8aEyxhe5gm6qy0qPIZRPd4DxFr4sBkj9Yx-4u8Bvy
      \endverb
      \verb{url}
      \verb https://dl.acm.org/doi/abs/10.1145/1390156.1390219?casa_token=ThkykpcwxJMAAAAA:m3YTBBF3m4J6caTUcl-CfITmu45s9R7G9BG8aEyxhe5gm6qy0qPIZRPd4DxFr4sBkj9Yx-4u8Bvy
      \endverb
    \endentry
    \entry{2009_Kondor_ICML}{inproceedings}{}
      \name{author}{3}{}{%
        {{hash=6abc8eb3beac1cdef82d485e69f760df}{%
           family={Kondor},
           familyi={K\bibinitperiod},
           given={Risi},
           giveni={R\bibinitperiod}}}%
        {{hash=23497b31a021c2543718505ff30158c5}{%
           family={Shervashidze},
           familyi={S\bibinitperiod},
           given={Nino},
           giveni={N\bibinitperiod}}}%
        {{hash=67b59c2b88bd10672a789826aedb1e91}{%
           family={Borgwardt},
           familyi={B\bibinitperiod},
           given={Karsten\bibnamedelima M.},
           giveni={K\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {{ACM} Press}%
      }
      \strng{namehash}{38c7a0538640079bfe8cf5ee1a911bb6}
      \strng{fullhash}{38c7a0538640079bfe8cf5ee1a911bb6}
      \strng{bibnamehash}{38c7a0538640079bfe8cf5ee1a911bb6}
      \strng{authorbibnamehash}{38c7a0538640079bfe8cf5ee1a911bb6}
      \strng{authornamehash}{38c7a0538640079bfe8cf5ee1a911bb6}
      \strng{authorfullhash}{38c7a0538640079bfe8cf5ee1a911bb6}
      \field{sortinit}{1}
      \field{sortinithash}{2174f786c6195e7fe2ee1c229b416e29}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Current graph kernels suffer from two limitations: graph kernels based on counting particular types of subgraphs ignore the relative position of these subgraphs to each other, while graph kernels based on algebraic methods are limited to graphs without node labels. In this paper we present the graphlet spectrum, a system of graph invariants derived by means of group representation theory that capture information about the number as well as the position of labeled subgraphs in a given graph. In our experimental evaluation the graphlet spectrum outperforms state-of-the-art graph kernels.}
      \field{booktitle}{Proceedings of the 26th Annual International Conference on Machine Learning - {ICML} {'}09}
      \field{title}{The graphlet spectrum}
      \field{year}{2009}
      \verb{doi}
      \verb 10.1145/1553374.1553443
      \endverb
      \verb{file}
      \verb :/home/fabrice/Documents/Uni/Literature/Papers/2009_Kondor_ICML.pdf:PDF
      \endverb
      \verb{urlraw}
      \verb https://dl.acm.org/doi/abs/10.1145/1553374.1553443?casa_token=8Gjtk3d-wi4AAAAA:FGaTCamElUgPOsW1kdH_nk6GsYAdtgvbCIf_5YHiqtn-Bw_VOKAPCVznogBNKJoSW5chXGR5uLBN
      \endverb
      \verb{url}
      \verb https://dl.acm.org/doi/abs/10.1145/1553374.1553443?casa_token=8Gjtk3d-wi4AAAAA:FGaTCamElUgPOsW1kdH_nk6GsYAdtgvbCIf_5YHiqtn-Bw_VOKAPCVznogBNKJoSW5chXGR5uLBN
      \endverb
    \endentry
    \entry{2009_Shervashidze_NIPS}{inproceedings}{}
      \name{author}{2}{}{%
        {{hash=23497b31a021c2543718505ff30158c5}{%
           family={Shervashidze},
           familyi={S\bibinitperiod},
           given={Nino},
           giveni={N\bibinitperiod}}}%
        {{hash=67b59c2b88bd10672a789826aedb1e91}{%
           family={Borgwardt},
           familyi={B\bibinitperiod},
           given={Karsten\bibnamedelima M.},
           giveni={K\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
      }
      \name{editor}{5}{}{%
        {{hash=40a8e4774982146adc2688546f54efb2}{%
           family={Bengio},
           familyi={B\bibinitperiod},
           given={Yoshua},
           giveni={Y\bibinitperiod}}}%
        {{hash=fc76f5fb256da4d423554f8e629b4321}{%
           family={Schuurmans},
           familyi={S\bibinitperiod},
           given={Dale},
           giveni={D\bibinitperiod}}}%
        {{hash=e1cbba7e1ec27d78a0784a5f6f63efc8}{%
           family={Lafferty},
           familyi={L\bibinitperiod},
           given={John\bibnamedelima D.},
           giveni={J\bibinitperiod\bibinitdelim D\bibinitperiod}}}%
        {{hash=18d5a61e673f86e548c1ea8a7f124c00}{%
           family={Williams},
           familyi={W\bibinitperiod},
           given={Christopher\bibnamedelimb K.\bibnamedelimi I.},
           giveni={C\bibinitperiod\bibinitdelim K\bibinitperiod\bibinitdelim I\bibinitperiod}}}%
        {{hash=0c6a0a8f357b4156dd16cb85784f4b8e}{%
           family={Culotta},
           familyi={C\bibinitperiod},
           given={Aron},
           giveni={A\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Curran Associates, Inc.}%
      }
      \strng{namehash}{0a0ff0347be6aff8d2e2c492ca1b13e9}
      \strng{fullhash}{0a0ff0347be6aff8d2e2c492ca1b13e9}
      \strng{bibnamehash}{0a0ff0347be6aff8d2e2c492ca1b13e9}
      \strng{authorbibnamehash}{0a0ff0347be6aff8d2e2c492ca1b13e9}
      \strng{authornamehash}{0a0ff0347be6aff8d2e2c492ca1b13e9}
      \strng{authorfullhash}{0a0ff0347be6aff8d2e2c492ca1b13e9}
      \strng{editorbibnamehash}{21e76644c7a1e15fa244bda873468cab}
      \strng{editornamehash}{21e76644c7a1e15fa244bda873468cab}
      \strng{editorfullhash}{20cee9107080cdb16ce033898ab7c1f7}
      \field{sortinit}{1}
      \field{sortinithash}{2174f786c6195e7fe2ee1c229b416e29}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In this article, we propose fast subtree kernels on graphs. On graphs with n nodes and m edges and maximum degree d, these kernels comparing subtrees of height h can be computed in O(mh), whereas the classic subtree kernel by Ramon & G¨artner scales as O(n24dh). Key to this efﬁciency is the observation that the Weisfeiler-Lehman test of isomorphism from graph theory elegantly computes a subtree kernel as a byproduct. Our fast subtree kernels can deal with labeled graphs, scale up easily to large graphs and outperform state-of-the-art graph ker- nels on several classiﬁcation benchmark datasets in terms of accuracy and runtime.}
      \field{booktitle}{Advances in Neural Information Processing Systems 22: 23rd Annual Conference on Neural Information Processing Systems 2009. Proceedings of a meeting held 7-10 December 2009, Vancouver, British Columbia, Canada}
      \field{title}{Fast subtree kernels on graphs}
      \field{year}{2009}
      \field{pages}{1660\bibrangedash 1668}
      \range{pages}{9}
      \verb{file}
      \verb :/home/fabrice/Documents/Uni/Literature/Papers/2009_Shervashidze_NIPS.pdf:PDF
      \endverb
      \verb{urlraw}
      \verb https://proceedings.neurips.cc/paper/2009/hash/0a49e3c3a03ebde64f85c0bacd8a08e2-Abstract.html
      \endverb
      \verb{url}
      \verb https://proceedings.neurips.cc/paper/2009/hash/0a49e3c3a03ebde64f85c0bacd8a08e2-Abstract.html
      \endverb
    \endentry
    \entry{1999_Haussler_CONF}{inproceedings}{}
      \name{author}{1}{}{%
        {{hash=b2ab6c3825f7511e8096e515df23c7e7}{%
           family={Haussler},
           familyi={H\bibinitperiod},
           given={David},
           giveni={D\bibinitperiod}}}%
      }
      \strng{namehash}{b2ab6c3825f7511e8096e515df23c7e7}
      \strng{fullhash}{b2ab6c3825f7511e8096e515df23c7e7}
      \strng{bibnamehash}{b2ab6c3825f7511e8096e515df23c7e7}
      \strng{authorbibnamehash}{b2ab6c3825f7511e8096e515df23c7e7}
      \strng{authornamehash}{b2ab6c3825f7511e8096e515df23c7e7}
      \strng{authorfullhash}{b2ab6c3825f7511e8096e515df23c7e7}
      \field{sortinit}{1}
      \field{sortinithash}{2174f786c6195e7fe2ee1c229b416e29}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We introduce a new method of constructing kernels on sets whose elements are discrete structures like strings, trees and graphs. The method can be applied iteratively to build a kernel on a in nite set from kernels involving generators of the set. The family of kernels generated generalizes the family of radial basis kernels. It can also be used to de ne kernels in the form of joint Gibbs probability distributions. Kernels can be built from hidden Markov random elds, generalized regular expressions, pair-HMMs, or ANOVA decompositions ...}
      \field{title}{Convolution Kernels on Discrete Structures}
      \field{year}{1999}
      \verb{file}
      \verb :/home/fabrice/Documents/Uni/Literature/Papers/1999_Haussler_CONF.pdf:PDF
      \endverb
      \verb{urlraw}
      \verb www.cse.ucsc.edu/haussler
      \endverb
      \verb{url}
      \verb www.cse.ucsc.edu/haussler
      \endverb
    \endentry
    \entry{2008_Hofmann_CONF}{article}{}
      \name{author}{3}{}{%
        {{hash=ee42cfed2ff3020233d2de97c356eaee}{%
           family={Hofmann},
           familyi={H\bibinitperiod},
           given={Thomas},
           giveni={T\bibinitperiod}}}%
        {{hash=ca31cc11ec9370460148c3a9c48fce45}{%
           family={Schölkopf},
           familyi={S\bibinitperiod},
           given={Bernhard},
           giveni={B\bibinitperiod}}}%
        {{hash=2df107c3366eadfba1b6ade0345e7fd2}{%
           family={Smola},
           familyi={S\bibinitperiod},
           given={Alexander\bibnamedelima J.},
           giveni={A\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Institute of Mathematical Statistics}%
      }
      \strng{namehash}{c7ff35407b2d493b66df4556ebbd8301}
      \strng{fullhash}{c7ff35407b2d493b66df4556ebbd8301}
      \strng{bibnamehash}{c7ff35407b2d493b66df4556ebbd8301}
      \strng{authorbibnamehash}{c7ff35407b2d493b66df4556ebbd8301}
      \strng{authornamehash}{c7ff35407b2d493b66df4556ebbd8301}
      \strng{authorfullhash}{c7ff35407b2d493b66df4556ebbd8301}
      \field{sortinit}{1}
      \field{sortinithash}{2174f786c6195e7fe2ee1c229b416e29}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We review machine learning methods employing positive definite kernels. These methods formulate learning and estimation problems in a reproducing kernel Hilbert space (RKHS) of functions defined on the data domain, expanded in terms of a kernel. Working in linear spaces of function has the benefit of facilitating the construction and analysis of learning algorithms while at the same time allowing large classes of functions. The latter include nonlinear functions as well as functions defined on nonvectorial data.}
      \field{journaltitle}{The Annals of Statistics}
      \field{month}{6}
      \field{number}{3}
      \field{title}{Kernel methods in machine learning}
      \field{volume}{36}
      \field{year}{2008}
      \verb{doi}
      \verb 10.1214/009053607000000677
      \endverb
      \verb{file}
      \verb :/home/fabrice/Documents/Uni/Literature/Papers/2008_Hofmann_CONF.pdf:PDF
      \endverb
      \verb{urlraw}
      \verb https://projecteuclid.org/journals/annals-of-statistics/volume-36/issue-3/Kernel-methods-in-machine-learning/10.1214/009053607000000677.full
      \endverb
      \verb{url}
      \verb https://projecteuclid.org/journals/annals-of-statistics/volume-36/issue-3/Kernel-methods-in-machine-learning/10.1214/009053607000000677.full
      \endverb
    \endentry
    \entry{2016_Kriege_NIPS}{inproceedings}{}
      \name{author}{6}{}{%
        {{hash=89fcc941314052e463fbdc6fa455bfa0}{%
           family={Kriege},
           familyi={K\bibinitperiod},
           given={Nils\bibnamedelima M.},
           giveni={N\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
        {{hash=7910a8c30093cfa372545a4deebf99a5}{%
           family={Giscard},
           familyi={G\bibinitperiod},
           given={Pierre-Louis},
           giveni={P\bibinithyphendelim L\bibinitperiod}}}%
        {{hash=2f3250f121557209f3b8231496d62527}{%
           family={Computer},
           familyi={C\bibinitperiod},
           given={Department},
           giveni={D\bibinitperiod},
           prefix={of},
           prefixi={o\bibinitperiod}}}%
        {{hash=1f0c3411fea9998f6a3d1696a5a56ca3}{%
           family={Department},
           familyi={D\bibinitperiod},
           given={Science},
           giveni={S\bibinitperiod}}}%
        {{hash=5b082f901e55579656f75c3d33a12036}{%
           family={Computer},
           familyi={C\bibinitperiod},
           prefix={of},
           prefixi={o\bibinitperiod}}}%
        {{hash=35bf1210e6727959a7a88a00462db959}{%
           family={Science},
           familyi={S\bibinitperiod}}}%
      }
      \strng{namehash}{b57bf4350e4f2bd3e5832daacdd0b466}
      \strng{fullhash}{89883cfaffe3d65b7daaa5beb63aaa12}
      \strng{bibnamehash}{b57bf4350e4f2bd3e5832daacdd0b466}
      \strng{authorbibnamehash}{b57bf4350e4f2bd3e5832daacdd0b466}
      \strng{authornamehash}{b57bf4350e4f2bd3e5832daacdd0b466}
      \strng{authorfullhash}{89883cfaffe3d65b7daaa5beb63aaa12}
      \field{sortinit}{1}
      \field{sortinithash}{2174f786c6195e7fe2ee1c229b416e29}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{The success of kernel methods has initiated the design of novel positive semidefinite functions, in particular for structured data. A leading design paradigm for this is the convolution kernel, which decomposes structured objects into their parts and sums over all pairs of parts. Assignment kernels, in contrast, are obtained from an optimal bijection between parts, which can provide a more valid notion of similarity. In general however, optimal assignments yield indefinite functions, which complicates their use in kernel methods. We characterize a class of base kernels used to compare parts that guarantees positive semidefinite optimal assignment kernels. These base kernels give rise to hierarchies from which the optimal assignment kernels are computed in linear time by histogram intersection. We apply these results by developing the Weisfeiler-Lehman optimal assignment kernel for graphs. It provides high classification accuracy on widely-used benchmark data sets improving over the original Weisfeiler-Lehman kernel.}
      \field{title}{On Valid Optimal Assignment Kernels and Applications to Graph Classification}
      \field{year}{2016}
      \verb{file}
      \verb :/home/fabrice/Documents/Uni/Literature/Papers/2016_Kriege_NIPS.pdf:PDF
      \endverb
    \endentry
    \entry{2019_Togninalli_NIPS}{inproceedings}{}
      \name{author}{4}{}{%
        {{hash=1ffa39f154f697cce71c499954e79340}{%
           family={Togninalli},
           familyi={T\bibinitperiod},
           given={Matteo},
           giveni={M\bibinitperiod}}}%
        {{hash=9ff92c27d6ada0f014238bcb7d4c4495}{%
           family={Ghisu},
           familyi={G\bibinitperiod},
           given={Elisabetta},
           giveni={E\bibinitperiod}}}%
        {{hash=f373c1b405034badf1248f26dc0f1f45}{%
           family={Llinares-López},
           familyi={L\bibinithyphendelim L\bibinitperiod},
           given={Felipe},
           giveni={F\bibinitperiod}}}%
        {{hash=444d8d5fcbebf11f920c4fd033f0bb40}{%
           family={Borgwardt},
           familyi={B\bibinitperiod},
           given={Karsten},
           giveni={K\bibinitperiod}}}%
      }
      \strng{namehash}{2031904e92c96d7f3cd5881495aa7f9f}
      \strng{fullhash}{30302765990c9d15daa38550f39b9ec5}
      \strng{bibnamehash}{2031904e92c96d7f3cd5881495aa7f9f}
      \strng{authorbibnamehash}{2031904e92c96d7f3cd5881495aa7f9f}
      \strng{authornamehash}{2031904e92c96d7f3cd5881495aa7f9f}
      \strng{authorfullhash}{30302765990c9d15daa38550f39b9ec5}
      \field{sortinit}{2}
      \field{sortinithash}{cbff857e587bcb4635511624d773949e}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Most graph kernels are an instance of the class of R-Convolution kernels, which measure the similarity of objects by comparing their substructures. Despite their empirical success, most graph kernels use a naive aggregation of the final set of substructures, usually a sum or average, thereby potentially discarding valuable information about the distribution of individual components. Furthermore, only a limited instance of these approaches can be extended to continuously attributed graphs. We propose a novel method that relies on the Wasserstein distance between the node feature vector distributions of two graphs, which allows finding subtler differences in data sets by considering graphs as high-dimensional objects rather than simple means. We further propose a Weisfeiler-Lehman-inspired embedding scheme for graphs with continuous node attributes and weighted edges, enhance it with the computed Wasserstein distance, and thereby improve the state-of-the-art prediction performance on several graph classification tasks.}
      \field{booktitle}{Advances in Neural Information Processing Systems 32 (NeurIPS 2019)}
      \field{title}{Wasserstein Weisfeiler-Lehman Graph Kernels}
      \field{year}{2019}
      \verb{file}
      \verb :/home/fabrice/Documents/Uni/Literature/Papers/2019_Togninalli_NIPS.pdf:PDF
      \endverb
      \verb{urlraw}
      \verb https://proceedings.neurips.cc/paper/2019/hash/73fed7fd472e502d8908794430511f4d-Abstract.html
      \endverb
      \verb{url}
      \verb https://proceedings.neurips.cc/paper/2019/hash/73fed7fd472e502d8908794430511f4d-Abstract.html
      \endverb
    \endentry
    \entry{2021_Schulz_CONF}{inproceedings}{}
      \name{author}{4}{}{%
        {{hash=6eff11b1bb1404670d22463a949fcaa0}{%
           family={Schulz},
           familyi={S\bibinitperiod},
           given={Till\bibnamedelima Hendrik},
           giveni={T\bibinitperiod\bibinitdelim H\bibinitperiod}}}%
        {{hash=028e7666b28474b3186d2efcfa20a8ef}{%
           family={Horváth},
           familyi={H\bibinitperiod},
           given={Tamás},
           giveni={T\bibinitperiod}}}%
        {{hash=60972706ebe48840b82ca646ffe3e72f}{%
           family={Welke},
           familyi={W\bibinitperiod},
           given={Pascal},
           giveni={P\bibinitperiod}}}%
        {{hash=9f8e62cad9a584bd2b54a6029652660f}{%
           family={Wrobel},
           familyi={W\bibinitperiod},
           given={Stefan},
           giveni={S\bibinitperiod}}}%
      }
      \strng{namehash}{ddf836b01c3494beeb36071633f4933a}
      \strng{fullhash}{3331bab6ed59eac555ac3d8be14f6309}
      \strng{bibnamehash}{ddf836b01c3494beeb36071633f4933a}
      \strng{authorbibnamehash}{ddf836b01c3494beeb36071633f4933a}
      \strng{authornamehash}{ddf836b01c3494beeb36071633f4933a}
      \strng{authorfullhash}{3331bab6ed59eac555ac3d8be14f6309}
      \field{sortinit}{2}
      \field{sortinithash}{cbff857e587bcb4635511624d773949e}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{The Weisfeiler-Lehman graph kernels are among the most prevalent graph kernels due to their remarkable time complexity and predictive performance. Their key concept is based on an implicit comparison of neighborhood repre- senting trees with respect to equality (i.e., isomorphism). This binary valued comparison is, however, arguably too rigid for defining suitable similarity measures over graphs. To overcome this limitation, we propose a generalization of Weisfeiler-Lehman graph kernels which takes into account the similarity between trees rather than equality. We achieve this using a specifically fitted variation of the well-known tree edit distance which can efficiently be calculated. We em- pirically show that our approach significantly outperforms state-of-the-art methods in terms of predictive performance on datasets containing structurally more complex graphs be- yond the typically considered molecular graphs}
      \field{title}{A Generalized Weisfeiler-Lehman Graph Kernel}
      \field{year}{2021}
      \verb{file}
      \verb :/home/fabrice/Documents/Uni/Literature/Papers/2021_Schulz_CONF.pdf:PDF
      \endverb
      \verb{urlraw}
      \verb https://arxiv.org/abs/2101.08104
      \endverb
      \verb{url}
      \verb https://arxiv.org/abs/2101.08104
      \endverb
    \endentry
    \entry{2005_Borgwardt_IEEE}{inproceedings}{}
      \name{author}{2}{}{%
        {{hash=444d8d5fcbebf11f920c4fd033f0bb40}{%
           family={Borgwardt},
           familyi={B\bibinitperiod},
           given={Karsten},
           giveni={K\bibinitperiod}}}%
        {{hash=9559fe65ed2c0877cf14a66fe1f8e9b3}{%
           family={Kriegel},
           familyi={K\bibinitperiod},
           given={Hans-Peter},
           giveni={H\bibinithyphendelim P\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {IEEE}%
      }
      \strng{namehash}{cb23d8ea89e42a30fbe28eaa114722e5}
      \strng{fullhash}{cb23d8ea89e42a30fbe28eaa114722e5}
      \strng{bibnamehash}{cb23d8ea89e42a30fbe28eaa114722e5}
      \strng{authorbibnamehash}{cb23d8ea89e42a30fbe28eaa114722e5}
      \strng{authornamehash}{cb23d8ea89e42a30fbe28eaa114722e5}
      \strng{authorfullhash}{cb23d8ea89e42a30fbe28eaa114722e5}
      \field{sortinit}{2}
      \field{sortinithash}{cbff857e587bcb4635511624d773949e}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{Fifth {IEEE} International Conference on Data Mining ({ICDM}{'}05)}
      \field{title}{Shortest-Path Kernels on Graphs}
      \field{year}{2005}
      \verb{doi}
      \verb 10.1109/icdm.2005.132
      \endverb
      \verb{file}
      \verb :2005_Borgwardt_IEEE - Shortest Path Kernels on Graphs.pdf:PDF
      \endverb
      \verb{urlraw}
      \verb https://ieeexplore.ieee.org/abstract/document/1565664
      \endverb
      \verb{url}
      \verb https://ieeexplore.ieee.org/abstract/document/1565664
      \endverb
    \endentry
    \entry{2003_Kashima_ICML}{inproceedings}{}
      \name{author}{3}{}{%
        {{hash=32fc6ae468e6012f7822868c12d9c044}{%
           family={Kashima},
           familyi={K\bibinitperiod},
           given={Hisashi},
           giveni={H\bibinitperiod}}}%
        {{hash=853aab53429db7bfeab5a5d15f06a51d}{%
           family={Tsuda},
           familyi={T\bibinitperiod},
           given={Koji},
           giveni={K\bibinitperiod}}}%
        {{hash=c28510f306df9f2fda376689c7195578}{%
           family={Inokuchi},
           familyi={I\bibinitperiod},
           given={Akihiro},
           giveni={A\bibinitperiod}}}%
      }
      \name{editor}{2}{}{%
        {{hash=9c15aa0b2a7683cefeaa12c991d0b1c2}{%
           family={Fawcett},
           familyi={F\bibinitperiod},
           given={Tom},
           giveni={T\bibinitperiod}}}%
        {{hash=5cc397067052b5802c5963e6da19708b}{%
           family={Mishra},
           familyi={M\bibinitperiod},
           given={Nina},
           giveni={N\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {{AAAI} Press}%
      }
      \strng{namehash}{3a056e2882bfff110d6f4c7ffefefaf1}
      \strng{fullhash}{3a056e2882bfff110d6f4c7ffefefaf1}
      \strng{bibnamehash}{3a056e2882bfff110d6f4c7ffefefaf1}
      \strng{authorbibnamehash}{3a056e2882bfff110d6f4c7ffefefaf1}
      \strng{authornamehash}{3a056e2882bfff110d6f4c7ffefefaf1}
      \strng{authorfullhash}{3a056e2882bfff110d6f4c7ffefefaf1}
      \strng{editorbibnamehash}{c5e531c527663062c6c481a4e2ad1a6b}
      \strng{editornamehash}{c5e531c527663062c6c481a4e2ad1a6b}
      \strng{editorfullhash}{c5e531c527663062c6c481a4e2ad1a6b}
      \field{sortinit}{2}
      \field{sortinithash}{cbff857e587bcb4635511624d773949e}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{A new kernel function between two labeled graphs is presented. Feature vectors are defined as the counts of label paths produced by random walks on graphs. The kernel computation finally boils down to obtaining the stationary state of a discrete-time linear system, thus is efficiently performed by solving simultaneous linear equations. Our kernel is based on an infinite dimensional feature space, so it is fundamentally different from other string or tree kernels based on dynamic programming. We will present promising empirical results in classification of chemical compounds.}
      \field{booktitle}{Machine Learning, Proceedings of the Twentieth International Conference {(ICML} 2003), August 21-24, 2003, Washington, DC, {USA}}
      \field{title}{Marginalized Kernels Between Labeled Graphs}
      \field{year}{2003}
      \field{pages}{321\bibrangedash 328}
      \range{pages}{8}
      \verb{file}
      \verb :2003_Kashima_CONF.pdf:PDF
      \endverb
      \verb{urlraw}
      \verb http://www.aaai.org/Library/ICML/2003/icml03-044.php
      \endverb
      \verb{url}
      \verb http://www.aaai.org/Library/ICML/2003/icml03-044.php
      \endverb
    \endentry
    \entry{2003_Gaertner_CONF}{incollection}{}
      \name{author}{3}{}{%
        {{hash=b4ecc68977acd188561a6e478c9d2c88}{%
           family={Gärtner},
           familyi={G\bibinitperiod},
           given={Thomas},
           giveni={T\bibinitperiod}}}%
        {{hash=715b97044ba694410083d16b5c29b92c}{%
           family={Flach},
           familyi={F\bibinitperiod},
           given={Peter},
           giveni={P\bibinitperiod}}}%
        {{hash=9f8e62cad9a584bd2b54a6029652660f}{%
           family={Wrobel},
           familyi={W\bibinitperiod},
           given={Stefan},
           giveni={S\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Springer Berlin Heidelberg}%
      }
      \strng{namehash}{290e9e8f8af757c7c776c9a6a962514a}
      \strng{fullhash}{290e9e8f8af757c7c776c9a6a962514a}
      \strng{bibnamehash}{290e9e8f8af757c7c776c9a6a962514a}
      \strng{authorbibnamehash}{290e9e8f8af757c7c776c9a6a962514a}
      \strng{authornamehash}{290e9e8f8af757c7c776c9a6a962514a}
      \strng{authorfullhash}{290e9e8f8af757c7c776c9a6a962514a}
      \field{sortinit}{2}
      \field{sortinithash}{cbff857e587bcb4635511624d773949e}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{As most ‘real-world’ data is structured, research in kernel methods has begun investigating kernels for various kinds of structured data. One of the most widely used tools for modeling structured data are graphs. An interesting and important challenge is thus to investigate kernels on instances that are represented by graphs. So far, only very specific graphs such as trees and strings have been considered. This paper investigates kernels on labeled directed graphs with general structure. It is shown that computing a strictly positive definite graph kernel is at least as hard as solving the graph isomorphism problem. It is also shown that computing an inner product in a feature space indexed by all possible graphs, where each feature counts the number of subgraphs isomorphic to that graph, is NP-hard. On the other hand, inner products in an alternative feature space, based on walks in the graph, can be computed in polynomial time. Such kernels are defined in this paper.}
      \field{booktitle}{Learning Theory and Kernel Machines}
      \field{title}{On Graph Kernels: Hardness Results and Efficient Alternatives}
      \field{year}{2003}
      \field{pages}{129\bibrangedash 143}
      \range{pages}{15}
      \verb{doi}
      \verb 10.1007/978-3-540-45167-9_11
      \endverb
      \verb{file}
      \verb :/home/fabrice/Documents/Uni/Literature/Papers/2003_Gaertner_CONF.pdf:PDF
      \endverb
      \verb{urlraw}
      \verb https://www.researchgate.net/publication/221497506_On_Graph_Kernels_Hardness_Results_and_Efficient_Alternatives
      \endverb
      \verb{url}
      \verb https://www.researchgate.net/publication/221497506_On_Graph_Kernels_Hardness_Results_and_Efficient_Alternatives
      \endverb
    \endentry
    \entry{2004_Horvath_KDD}{inproceedings}{}
      \name{author}{3}{}{%
        {{hash=ac6c25478e2dce34e35e9cf93feac18d}{%
           family={Horv{á}th},
           familyi={H\bibinitperiod},
           given={Tam{á}s},
           giveni={T\bibinitperiod}}}%
        {{hash=b4ecc68977acd188561a6e478c9d2c88}{%
           family={Gärtner},
           familyi={G\bibinitperiod},
           given={Thomas},
           giveni={T\bibinitperiod}}}%
        {{hash=9f8e62cad9a584bd2b54a6029652660f}{%
           family={Wrobel},
           familyi={W\bibinitperiod},
           given={Stefan},
           giveni={S\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {{ACM} Press}%
      }
      \strng{namehash}{df4688b29d4c8632586ad924c0b55ced}
      \strng{fullhash}{df4688b29d4c8632586ad924c0b55ced}
      \strng{bibnamehash}{df4688b29d4c8632586ad924c0b55ced}
      \strng{authorbibnamehash}{df4688b29d4c8632586ad924c0b55ced}
      \strng{authornamehash}{df4688b29d4c8632586ad924c0b55ced}
      \strng{authorfullhash}{df4688b29d4c8632586ad924c0b55ced}
      \field{sortinit}{2}
      \field{sortinithash}{cbff857e587bcb4635511624d773949e}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{With applications in biology, the world-wide web, and several other areas, mining of graph-structured objects has received significant interest recently. One of the major research directions in this field is concerned with predictive data mining in graph databases where each instance is represented by a graph. Some of the proposed approaches for this task rely on the excellent classification performance of support vector machines. To control the computational cost of these approaches, the underlying kernel functions are based on frequent patterns. In contrast to these approaches, we propose a kernel function based on a natural set of cyclic and tree patterns independent of their frequency, and discuss its computational aspects. To practically demonstrate the effectiveness of our approach, we use the popular NCI-HIV molecule dataset. Our experimental results show that cyclic pattern kernels can be computed quickly and offer predictive performance superior to recent graph kernels based on frequent patterns.}
      \field{booktitle}{Proceedings of the 2004 {ACM} {SIGKDD} international conference on Knowledge discovery and data mining - {KDD} {'}04}
      \field{title}{Cyclic pattern kernels for predictive graph mining}
      \field{year}{2004}
      \verb{doi}
      \verb 10.1145/1014052.1014072
      \endverb
      \verb{file}
      \verb :/home/fabrice/Documents/Uni/Literature/Papers/2004_Horvath_KDD.pdf:PDF
      \endverb
      \verb{urlraw}
      \verb https://dl.acm.org/doi/abs/10.1145/1014052.1014072?casa_token=CIWeyKbVeBIAAAAA:6wXc6LcbwjQw2NOkKa_lLTSIMh3VJGreIYenhd7fggC1WkeGKShZ7ICSgfMXakm8jhJfnzJtTK7b
      \endverb
      \verb{url}
      \verb https://dl.acm.org/doi/abs/10.1145/1014052.1014072?casa_token=CIWeyKbVeBIAAAAA:6wXc6LcbwjQw2NOkKa_lLTSIMh3VJGreIYenhd7fggC1WkeGKShZ7ICSgfMXakm8jhJfnzJtTK7b
      \endverb
    \endentry
    \entry{2003_Ramon_CONF}{inproceedings}{}
      \name{author}{2}{}{%
        {{hash=253229d8260fd72b6511b998d1879602}{%
           family={Ramon},
           familyi={R\bibinitperiod},
           given={Jan},
           giveni={J\bibinitperiod}}}%
        {{hash=10d2fd9a4b0b4d431b99e2d413e0c477}{%
           family={Gartner},
           familyi={G\bibinitperiod},
           given={Thomas},
           giveni={T\bibinitperiod}}}%
      }
      \strng{namehash}{7d8a6f3a48d7de862bd5273f387995a1}
      \strng{fullhash}{7d8a6f3a48d7de862bd5273f387995a1}
      \strng{bibnamehash}{7d8a6f3a48d7de862bd5273f387995a1}
      \strng{authorbibnamehash}{7d8a6f3a48d7de862bd5273f387995a1}
      \strng{authornamehash}{7d8a6f3a48d7de862bd5273f387995a1}
      \strng{authorfullhash}{7d8a6f3a48d7de862bd5273f387995a1}
      \field{sortinit}{3}
      \field{sortinithash}{a4b52e5432884761f50fb9571273b93e}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Recently, kernel methods have become a popular tool for ma- chine learning and data mining. As most real-world' data is structured, research in kernel methods has begun investigating kernels for various kinds of structured data. One of the most widely used tools for modeling structured data are graphs. In this paper we study the trade-off between expressivity and eciency of graph kernels. First, we motivate the need for this discussion by showing that fully general graph kernels can not even be approximated eciently. We also discuss generalizations of graph kernels defined in literature and show that they are either not positive definite or not very useful. Finally, we propose a new graph kernel based on subtree patterns. We argue that while a little more computationally expensive, this kernel is more expressive than kernels based on walks.}
      \field{booktitle}{Proceedings of the First International Workshop on Mining Graphs, Trees and Sequences}
      \field{title}{Expressivity versus Efficienvy of Graph Kernels}
      \field{year}{2003}
      \verb{file}
      \verb :/home/fabrice/Documents/Uni/Literature/Papers/2003_Ramon_CONF.pdf:PDF
      \endverb
      \verb{urlraw}
      \verb https://www.researchgate.net/publication/244401794_Expressivity_versus_Eciency_of_Graph_Kernels
      \endverb
      \verb{url}
      \verb https://www.researchgate.net/publication/244401794_Expressivity_versus_Eciency_of_Graph_Kernels
      \endverb
    \endentry
    \entry{2008_Mahe_CONF}{article}{}
      \name{author}{2}{}{%
        {{hash=d2c399537d8d98e5b016687c578f1ad9}{%
           family={Mah{é}},
           familyi={M\bibinitperiod},
           given={Pierre},
           giveni={P\bibinitperiod}}}%
        {{hash=0df2e0c86d89bfaf4f3726c0bc382d4f}{%
           family={Vert},
           familyi={V\bibinitperiod},
           given={Jean-Philippe},
           giveni={J\bibinithyphendelim P\bibinitperiod}}}%
      }
      \list{publisher}{2}{%
        {Springer Science}%
        {Business Media {LLC}}%
      }
      \strng{namehash}{2809736f450514584fb60a3665d4d143}
      \strng{fullhash}{2809736f450514584fb60a3665d4d143}
      \strng{bibnamehash}{2809736f450514584fb60a3665d4d143}
      \strng{authorbibnamehash}{2809736f450514584fb60a3665d4d143}
      \strng{authornamehash}{2809736f450514584fb60a3665d4d143}
      \strng{authorfullhash}{2809736f450514584fb60a3665d4d143}
      \field{sortinit}{3}
      \field{sortinithash}{a4b52e5432884761f50fb9571273b93e}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Motivated by chemical applications, we revisit and extend a family of positive definite kernels for graphs based on the detection of common subtrees, initially proposed by Ramon and Gärtner (Proceedings of the first international workshop on mining graphs, trees and sequences, pp. 65-74, 2003). We propose new kernels with a parameter to control the complexity of the subtrees used as features to represent the graphs. This parameter allows to smoothly interpolate between classical graph kernels based on the count of common walks, on the one hand, and kernels that emphasize the detection of large common subtrees, on the other hand. We also propose two modular extensions to this formulation. The first extension increases the number of subtrees that define the feature space, and the second one removes noisy features from the graph representations. We validate experimentally these new kernels on problems of toxicity and anti-cancer activity prediction for small molecules with support vector machines.}
      \field{journaltitle}{Machine Learning}
      \field{month}{10}
      \field{number}{1}
      \field{title}{Graph kernels based on tree patterns for molecules}
      \field{volume}{75}
      \field{year}{2008}
      \field{pages}{3\bibrangedash 35}
      \range{pages}{33}
      \verb{doi}
      \verb 10.1007/s10994-008-5086-2
      \endverb
      \verb{file}
      \verb :/home/fabrice/Documents/Uni/Literature/Papers/2008_Mahé_CONF.pdf:PDF
      \endverb
      \verb{urlraw}
      \verb https://link.springer.com/article/10.1007/s10994-008-5086-2
      \endverb
      \verb{url}
      \verb https://link.springer.com/article/10.1007/s10994-008-5086-2
      \endverb
      \keyw{Graph kernels · Support vector machines · Chemoinformatics}
    \endentry
    \entry{2012_Kobler_BOOK}{book}{}
      \name{author}{3}{}{%
        {{hash=be52398a011893d529d2bb17bdb20552}{%
           family={Kobler},
           familyi={K\bibinitperiod},
           given={Johannes},
           giveni={J\bibinitperiod}}}%
        {{hash=992dee2cdc1f0a62ec5e694fbbd6e2c2}{%
           family={Sch{ö}ning},
           familyi={S\bibinitperiod},
           given={Uwe},
           giveni={U\bibinitperiod}}}%
        {{hash=e24d5bd850de34d825fad09786128485}{%
           family={Tor{á}n},
           familyi={T\bibinitperiod},
           given={Jacobo},
           giveni={J\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Springer Science \& Business Media}%
      }
      \strng{namehash}{3eb4a7bb9b7079a8ce9b894445f1ac16}
      \strng{fullhash}{3eb4a7bb9b7079a8ce9b894445f1ac16}
      \strng{bibnamehash}{3eb4a7bb9b7079a8ce9b894445f1ac16}
      \strng{authorbibnamehash}{3eb4a7bb9b7079a8ce9b894445f1ac16}
      \strng{authornamehash}{3eb4a7bb9b7079a8ce9b894445f1ac16}
      \strng{authorfullhash}{3eb4a7bb9b7079a8ce9b894445f1ac16}
      \field{sortinit}{3}
      \field{sortinithash}{a4b52e5432884761f50fb9571273b93e}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{title}{The graph isomorphism problem: its structural complexity}
      \field{year}{2012}
    \endentry
    \entry{2002_Gartner_NIPS}{inproceedings}{}
      \name{author}{1}{}{%
        {{hash=29b073261566a31f22d7d1165e99c34c}{%
           family={Gartner},
           familyi={G\bibinitperiod},
           given={T.},
           giveni={T\bibinitperiod}}}%
      }
      \strng{namehash}{29b073261566a31f22d7d1165e99c34c}
      \strng{fullhash}{29b073261566a31f22d7d1165e99c34c}
      \strng{bibnamehash}{29b073261566a31f22d7d1165e99c34c}
      \strng{authorbibnamehash}{29b073261566a31f22d7d1165e99c34c}
      \strng{authornamehash}{29b073261566a31f22d7d1165e99c34c}
      \strng{authorfullhash}{29b073261566a31f22d7d1165e99c34c}
      \field{sortinit}{3}
      \field{sortinithash}{a4b52e5432884761f50fb9571273b93e}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{NIPS\^{}* 02 Workshop on Unreal Data: Principles of Modeling Nonvectorial Data}
      \field{title}{Exponential and geometric kernels for graphs}
      \field{year}{2002}
    \endentry
    \entry{2004_Kuramochi_IEEE}{article}{}
      \name{author}{2}{}{%
        {{hash=122d5c60d44fd36680a399abb985289f}{%
           family={Kuramochi},
           familyi={K\bibinitperiod},
           given={M.},
           giveni={M\bibinitperiod}}}%
        {{hash=eb16d86801a2137442a714da26cb9588}{%
           family={Karypis},
           familyi={K\bibinitperiod},
           given={G.},
           giveni={G\bibinitperiod}}}%
      }
      \list{publisher}{2}{%
        {Institute of Electrical}%
        {Electronics Engineers ({IEEE})}%
      }
      \strng{namehash}{39f876318857b697f4ebfce5e8429633}
      \strng{fullhash}{39f876318857b697f4ebfce5e8429633}
      \strng{bibnamehash}{39f876318857b697f4ebfce5e8429633}
      \strng{authorbibnamehash}{39f876318857b697f4ebfce5e8429633}
      \strng{authornamehash}{39f876318857b697f4ebfce5e8429633}
      \strng{authorfullhash}{39f876318857b697f4ebfce5e8429633}
      \field{sortinit}{3}
      \field{sortinithash}{a4b52e5432884761f50fb9571273b93e}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Over the years, frequent itemset discovery algorithms have been used to find interesting patterns in various application areas. However, as data mining techniques are being increasingly applied to nontraditional domains, existing frequent pattern discovery approaches cannot be used. This is because the transaction framework that is assumed by these algorithms cannot be used to effectively model the data sets in these domains. An alternate way of modeling the objects in these data sets is to represent them using graphs. Within that model, one way of formulating the frequent pattern discovery problem is that of discovering subgraphs that occur frequently over the entire set of graphs. We present a computationally efficient algorithm, called FSG, for finding all frequent subgraphs in large graph data sets. We experimentally evaluate the performance of FSG using a variety of real and synthetic data sets. Our results show that despite the underlying complexity associated with frequent subgraph discovery, FSG is effective in finding all frequently occurring subgraphs in data sets containing more than 200,000 graph transactions and scales linearly with respect to the size of the data set.}
      \field{journaltitle}{{IEEE} Transactions on Knowledge and Data Engineering}
      \field{month}{9}
      \field{number}{9}
      \field{title}{An efficient algorithm for discovering frequent subgraphs}
      \field{volume}{16}
      \field{year}{2004}
      \field{pages}{1038\bibrangedash 1051}
      \range{pages}{14}
      \verb{doi}
      \verb 10.1109/tkde.2004.33
      \endverb
      \verb{file}
      \verb :2004_Kuramochi_IEEE.pdf:PDF
      \endverb
      \verb{urlraw}
      \verb https://www.semanticscholar.org/paper/An-efficient-algorithm-for-discovering-frequent-Kuramochi-Karypis/77259f9b60901545f6f882d682870bb0aa067566
      \endverb
      \verb{url}
      \verb https://www.semanticscholar.org/paper/An-efficient-algorithm-for-discovering-frequent-Kuramochi-Karypis/77259f9b60901545f6f882d682870bb0aa067566
      \endverb
    \endentry
    \entry{2009_Shervashidze_PMLR}{inproceedings}{}
      \name{author}{5}{}{%
        {{hash=23497b31a021c2543718505ff30158c5}{%
           family={Shervashidze},
           familyi={S\bibinitperiod},
           given={Nino},
           giveni={N\bibinitperiod}}}%
        {{hash=50229a0f87f08a1fdc1e052ba8c93735}{%
           family={Vishwanathan},
           familyi={V\bibinitperiod},
           given={SVN},
           giveni={S\bibinitperiod}}}%
        {{hash=b68b70ee7d59cb0432cf48a420b6f3b0}{%
           family={Petri},
           familyi={P\bibinitperiod},
           given={Tobias},
           giveni={T\bibinitperiod}}}%
        {{hash=c2f239e3cf9c48b72ce5f4ca9b5e478e}{%
           family={Mehlhorn},
           familyi={M\bibinitperiod},
           given={Kurt},
           giveni={K\bibinitperiod}}}%
        {{hash=444d8d5fcbebf11f920c4fd033f0bb40}{%
           family={Borgwardt},
           familyi={B\bibinitperiod},
           given={Karsten},
           giveni={K\bibinitperiod}}}%
      }
      \strng{namehash}{e43ca9e51cdcd7aa361fb11055875ddc}
      \strng{fullhash}{6c1a65f2d20e9acc281347809e9840d0}
      \strng{bibnamehash}{e43ca9e51cdcd7aa361fb11055875ddc}
      \strng{authorbibnamehash}{e43ca9e51cdcd7aa361fb11055875ddc}
      \strng{authornamehash}{e43ca9e51cdcd7aa361fb11055875ddc}
      \strng{authorfullhash}{6c1a65f2d20e9acc281347809e9840d0}
      \field{sortinit}{4}
      \field{sortinithash}{11cdaee3b18e01d77f3f428b13c1fc76}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{State-of-the-art graph kernels do not scale to large graphs with hundreds of nodes and thousands of edges. In this article we propose to compare graphs by counting graphlets, i.e., subgraphs with k nodes where k∈{3,4,5}. Exhaustive enumeration of all graphlets being prohibitively expensive, we introduce two theoretically grounded speedup schemes, one based on sampling and the second one specifically designed for bounded degree graphs. In our experimental evaluation, our novel kernels allow us to efficiently compare large graphs that cannot be tackled by existing graph kernels.}
      \field{title}{Efficient graphlet kernels for large graph comparison}
      \field{year}{2009}
      \verb{file}
      \verb :/home/fabrice/Documents/Uni/Literature/Papers/2009_Shervashidze_PMLR.pdf:PDF
      \endverb
      \verb{urlraw}
      \verb https://proceedings.mlr.press/v5/shervashidze09a.html
      \endverb
      \verb{url}
      \verb https://proceedings.mlr.press/v5/shervashidze09a.html
      \endverb
    \endentry
    \entry{2016_Kersting_CONF}{article}{}
      \name{author}{5}{}{%
        {{hash=231ca1992b128d48dbc73100fd196d87}{%
           family={Kersting},
           familyi={K\bibinitperiod},
           given={Kristian},
           giveni={K\bibinitperiod}}}%
        {{hash=89fcc941314052e463fbdc6fa455bfa0}{%
           family={Kriege},
           familyi={K\bibinitperiod},
           given={Nils\bibnamedelima M.},
           giveni={N\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
        {{hash=85f1d306bd524b1b382661ffd4da38e8}{%
           family={Morris},
           familyi={M\bibinitperiod},
           given={Christopher},
           giveni={C\bibinitperiod}}}%
        {{hash=a2fd7e6fca32deb028c924ba80cfa4df}{%
           family={Mutzel},
           familyi={M\bibinitperiod},
           given={Petra},
           giveni={P\bibinitperiod}}}%
        {{hash=1b772f8e40b5084f26030e1f86a6842a}{%
           family={Neumann},
           familyi={N\bibinitperiod},
           given={Marion},
           giveni={M\bibinitperiod}}}%
      }
      \strng{namehash}{08d337f2446491a72e543e304d1aa534}
      \strng{fullhash}{a1753146b931e098cab301e62089c8dd}
      \strng{bibnamehash}{08d337f2446491a72e543e304d1aa534}
      \strng{authorbibnamehash}{08d337f2446491a72e543e304d1aa534}
      \strng{authornamehash}{08d337f2446491a72e543e304d1aa534}
      \strng{authorfullhash}{a1753146b931e098cab301e62089c8dd}
      \field{sortinit}{5}
      \field{sortinithash}{3c19c3776b658b3558e9e2e4840c01e2}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{title}{Benchmark data sets for graph kernels}
      \field{year}{2016}
    \endentry
    \entry{2020_Morris_CONF}{inproceedings}{}
      \name{author}{6}{}{%
        {{hash=85f1d306bd524b1b382661ffd4da38e8}{%
           family={Morris},
           familyi={M\bibinitperiod},
           given={Christopher},
           giveni={C\bibinitperiod}}}%
        {{hash=89fcc941314052e463fbdc6fa455bfa0}{%
           family={Kriege},
           familyi={K\bibinitperiod},
           given={Nils\bibnamedelima M.},
           giveni={N\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
        {{hash=70808e13adb015e038aba29fde8e6466}{%
           family={Bause},
           familyi={B\bibinitperiod},
           given={Franka},
           giveni={F\bibinitperiod}}}%
        {{hash=231ca1992b128d48dbc73100fd196d87}{%
           family={Kersting},
           familyi={K\bibinitperiod},
           given={Kristian},
           giveni={K\bibinitperiod}}}%
        {{hash=a2fd7e6fca32deb028c924ba80cfa4df}{%
           family={Mutzel},
           familyi={M\bibinitperiod},
           given={Petra},
           giveni={P\bibinitperiod}}}%
        {{hash=1b772f8e40b5084f26030e1f86a6842a}{%
           family={Neumann},
           familyi={N\bibinitperiod},
           given={Marion},
           giveni={M\bibinitperiod}}}%
      }
      \strng{namehash}{9c39ef4db36e59a83a742c64db10697f}
      \strng{fullhash}{f26e49b1f69e16e64a78d5c9f2969633}
      \strng{bibnamehash}{9c39ef4db36e59a83a742c64db10697f}
      \strng{authorbibnamehash}{9c39ef4db36e59a83a742c64db10697f}
      \strng{authornamehash}{9c39ef4db36e59a83a742c64db10697f}
      \strng{authorfullhash}{f26e49b1f69e16e64a78d5c9f2969633}
      \field{sortinit}{5}
      \field{sortinithash}{3c19c3776b658b3558e9e2e4840c01e2}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Recently, there has been an increasing interest in (supervised) learning with graph data, especially using graph neural networks. However, the development of meaningful benchmark datasets and standardized evaluation procedures is lagging, consequently hindering advancements in this area. To address this, we introduce the TUDataset for graph classification and regression. The collection consists of over 120 datasets of varying sizes from a wide range of applications. We provide Python-based data loaders, kernel and graph neural network baseline implementations, and evaluation tools. Here, we give an overview of the datasets, standardized evaluation procedures, and provide baseline experiments. All datasets are available at this http URL. The experiments are fully reproducible from the code available at this http URL.}
      \field{title}{{TUD}ataset: A collection of benchmark datasets for learning with graphs}
      \field{year}{2020}
      \verb{file}
      \verb :/home/fabrice/Documents/Uni/Literature/Papers/2020_Morris_CONF.pdf:PDF
      \endverb
      \verb{urlraw}
      \verb https://arxiv.org/abs/2007.08663
      \endverb
      \verb{url}
      \verb https://arxiv.org/abs/2007.08663
      \endverb
      \keyw{graph learning,graph kernel,weisfeiler,leman,gnn,graph neural network,benchmark datasets}
    \endentry
    \entry{2010_Vishwanathan_CONF}{article}{}
      \name{author}{4}{}{%
        {{hash=c6c55d54ac2f6e80ad25f40ce461fa3f}{%
           family={Vishwanathan},
           familyi={V\bibinitperiod},
           given={S.\bibnamedelimi Vichy\bibnamedelima N.},
           giveni={S\bibinitperiod\bibinitdelim V\bibinitperiod\bibinitdelim N\bibinitperiod}}}%
        {{hash=0367e8bd9ffb62134583c5acb0b09ff9}{%
           family={Schraudolph},
           familyi={S\bibinitperiod},
           given={Nicol\bibnamedelima N.},
           giveni={N\bibinitperiod\bibinitdelim N\bibinitperiod}}}%
        {{hash=6abc8eb3beac1cdef82d485e69f760df}{%
           family={Kondor},
           familyi={K\bibinitperiod},
           given={Risi},
           giveni={R\bibinitperiod}}}%
        {{hash=67b59c2b88bd10672a789826aedb1e91}{%
           family={Borgwardt},
           familyi={B\bibinitperiod},
           given={Karsten\bibnamedelima M.},
           giveni={K\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {MIT Press}%
      }
      \strng{namehash}{461a48afa041553823e7319133724ca4}
      \strng{fullhash}{48b3c37ae3e65b6d0acf37f95c9c8d9e}
      \strng{bibnamehash}{461a48afa041553823e7319133724ca4}
      \strng{authorbibnamehash}{461a48afa041553823e7319133724ca4}
      \strng{authornamehash}{461a48afa041553823e7319133724ca4}
      \strng{authorfullhash}{48b3c37ae3e65b6d0acf37f95c9c8d9e}
      \field{sortinit}{5}
      \field{sortinithash}{3c19c3776b658b3558e9e2e4840c01e2}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{Journal of Machine Learning Research}
      \field{title}{Graph kernels}
      \field{volume}{11}
      \field{year}{2010}
      \field{pages}{1201\bibrangedash 1242}
      \range{pages}{42}
    \endentry
    \entry{2005_Gori_IEEE}{article}{}
      \name{author}{3}{}{%
        {{hash=24a6f526bae1303a16c25a75df57f22b}{%
           family={Gori},
           familyi={G\bibinitperiod},
           given={M.},
           giveni={M\bibinitperiod}}}%
        {{hash=8f5e57f4289a87a56ddbcdbf33341b14}{%
           family={Maggini},
           familyi={M\bibinitperiod},
           given={M.},
           giveni={M\bibinitperiod}}}%
        {{hash=2033afed6a9ace86327f0aa069d80e04}{%
           family={Sarti},
           familyi={S\bibinitperiod},
           given={L.},
           giveni={L\bibinitperiod}}}%
      }
      \list{publisher}{2}{%
        {Institute of Electrical}%
        {Electronics Engineers ({IEEE})}%
      }
      \strng{namehash}{daddc2e1efcdd4e0d655d36f91f3d019}
      \strng{fullhash}{daddc2e1efcdd4e0d655d36f91f3d019}
      \strng{bibnamehash}{daddc2e1efcdd4e0d655d36f91f3d019}
      \strng{authorbibnamehash}{daddc2e1efcdd4e0d655d36f91f3d019}
      \strng{authornamehash}{daddc2e1efcdd4e0d655d36f91f3d019}
      \strng{authorfullhash}{daddc2e1efcdd4e0d655d36f91f3d019}
      \field{sortinit}{5}
      \field{sortinithash}{3c19c3776b658b3558e9e2e4840c01e2}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In this paper, we propose a general framework for graph matching which is suitable for different problems of pattern recognition. The pattern representation we assume is at the same time highly structured, like for classic syntactic and structural approaches, and of subsymbolic nature with real-valued features, like for connectionist and statistic approaches. We show that random walk based models, inspired by Google's PageRank, give rise to a spectral theory that nicely enhances the graph topological features at node level. As a straightforward consequence, we derive a polynomial algorithm for the classic graph isomorphism problem, under the restriction of dealing with Markovian spectrally distinguishable graphs (MSD), a class of graphs that does not seem to be easily reducible to others proposed in the literature. The experimental results that we found on different test-beds of the TC-15 graph database show that the defined MSD class "almost always" covers the database, and that the proposed algorithm is significantly more efficient than top scoring VF algorithm on the same data. Most interestingly, the proposed approach is very well-suited for dealing with partial and approximate graph matching problems, derived for instance from image retrieval tasks. We consider the objects of the COIL-100 visual collection and provide a graph-based representation, whose node's labels contain appropriate visual features. We show that the adoption of classic bipartite graph matching algorithms offers a straightforward generalization of the algorithm given for graph isomorphism and, finally, we report very promising experimental results on the COIL-100 visual collection.}
      \field{journaltitle}{{IEEE} Transactions on Pattern Analysis and Machine Intelligence}
      \field{month}{7}
      \field{number}{7}
      \field{title}{Exact and approximate graph matching using random walks}
      \field{volume}{27}
      \field{year}{2005}
      \field{pages}{1100\bibrangedash 1111}
      \range{pages}{12}
      \verb{doi}
      \verb 10.1109/tpami.2005.138
      \endverb
    \endentry
    \entry{2009_Riesen_CONF}{article}{}
      \name{author}{2}{}{%
        {{hash=2baff21a8dd8f41605ec19a4057557fb}{%
           family={Riesen},
           familyi={R\bibinitperiod},
           given={Kaspar},
           giveni={K\bibinitperiod}}}%
        {{hash=625c3a38db540fc74378c3ebda8cda48}{%
           family={Bunke},
           familyi={B\bibinitperiod},
           given={Horst},
           giveni={H\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Elsevier {BV}}%
      }
      \strng{namehash}{7c72451cb96deeb7e9f765ab868b0bd9}
      \strng{fullhash}{7c72451cb96deeb7e9f765ab868b0bd9}
      \strng{bibnamehash}{7c72451cb96deeb7e9f765ab868b0bd9}
      \strng{authorbibnamehash}{7c72451cb96deeb7e9f765ab868b0bd9}
      \strng{authornamehash}{7c72451cb96deeb7e9f765ab868b0bd9}
      \strng{authorfullhash}{7c72451cb96deeb7e9f765ab868b0bd9}
      \field{sortinit}{5}
      \field{sortinithash}{3c19c3776b658b3558e9e2e4840c01e2}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In recent years, the use of graph based object representation has gained popularity. Simultaneously, graph edit distance emerged as a powerful and flexible graph matching paradigm that can be used to address different tasks in pattern recognition, machine learning, and data mining. The key advantages of graph edit distance are its high degree of flexibility, which makes it applicable to any type of graph, and the fact that one can integrate domain specific knowledge about object similarity by means of specific edit cost functions. Its computational complexity, however, is exponential in the number of nodes of the involved graphs. Consequently, exact graph edit distance is feasible for graphs of rather small size only. In the present paper we introduce a novel algorithm which allows us to approximately, or suboptimally, compute edit distance in a substantially faster way. The proposed algorithm considers only local, rather than global, edge structure during the optimization process. In experiments on different datasets we demonstrate a substantial speed-up of our proposed method over two reference systems. Moreover, it is emprically verified that the accuracy of the suboptimal distance remains sufficiently accurate for various pattern recognition applications.}
      \field{journaltitle}{Image and Vision Computing}
      \field{month}{6}
      \field{number}{7}
      \field{title}{Approximate graph edit distance computation by means of bipartite graph matching}
      \field{volume}{27}
      \field{year}{2009}
      \field{pages}{950\bibrangedash 959}
      \range{pages}{10}
      \verb{doi}
      \verb 10.1016/j.imavis.2008.04.004
      \endverb
    \endentry
    \entry{2015_Schiavinato_CONF}{incollection}{}
      \name{author}{3}{}{%
        {{hash=80b4751228b2e369f687c301fe65cdd6}{%
           family={Schiavinato},
           familyi={S\bibinitperiod},
           given={Michele},
           giveni={M\bibinitperiod}}}%
        {{hash=474597c7d87d2dcc60ac358651154815}{%
           family={Gasparetto},
           familyi={G\bibinitperiod},
           given={Andrea},
           giveni={A\bibinitperiod}}}%
        {{hash=e17a533eaf94f618bc80ad9352063e49}{%
           family={Torsello},
           familyi={T\bibinitperiod},
           given={Andrea},
           giveni={A\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Springer International Publishing}%
      }
      \strng{namehash}{ffe8c3dd07dd1a114a189b805e4d9538}
      \strng{fullhash}{ffe8c3dd07dd1a114a189b805e4d9538}
      \strng{bibnamehash}{ffe8c3dd07dd1a114a189b805e4d9538}
      \strng{authorbibnamehash}{ffe8c3dd07dd1a114a189b805e4d9538}
      \strng{authornamehash}{ffe8c3dd07dd1a114a189b805e4d9538}
      \strng{authorfullhash}{ffe8c3dd07dd1a114a189b805e4d9538}
      \field{sortinit}{5}
      \field{sortinithash}{3c19c3776b658b3558e9e2e4840c01e2}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Kernel methods provide a convenient way to apply a wide range of learning techniques to complex and structured data by shifting the representational problem from one of finding an embedding of the data to that of defining a positive semi-definite kernel. One problem with the most widely used kernels is that they neglect the locational information within the structures, resulting in less discrimination. Correspondence-based kernels, on the other hand, are in general more discriminating, at the cost of sacrificing positive-definiteness due to their inability to guarantee transitivity of the correspondences between multiple graphs. In this paper we adopt a general framework for the projection of (relaxed) correspondences onto the space of transitive correspondences, thus transforming any given matching algorithm onto a transitive multi-graph matching approach. The resulting transitive correspondences can then be used to provide a kernel that both maintains locational information and is guaranteed to be positive-definite. Experimental evaluation validates the effectiveness of the kernel for several structural classification tasks.}
      \field{booktitle}{Similarity-Based Pattern Recognition}
      \field{title}{Transitive Assignment Kernels for Structural Classification}
      \field{year}{2015}
      \field{pages}{146\bibrangedash 159}
      \range{pages}{14}
      \verb{doi}
      \verb 10.1007/978-3-319-24261-3_12
      \endverb
    \endentry
    \entry{2007_Wale_CONF}{article}{}
      \name{author}{3}{}{%
        {{hash=2c3ff55060e9296ccc03b7ddd76619d6}{%
           family={Wale},
           familyi={W\bibinitperiod},
           given={Nikil},
           giveni={N\bibinitperiod}}}%
        {{hash=76e3b292b00d0633cbba6f1a47b3ea4c}{%
           family={Watson},
           familyi={W\bibinitperiod},
           given={Ian\bibnamedelima A.},
           giveni={I\bibinitperiod\bibinitdelim A\bibinitperiod}}}%
        {{hash=3db7df6401b206bb040d6735adbe81e2}{%
           family={Karypis},
           familyi={K\bibinitperiod},
           given={George},
           giveni={G\bibinitperiod}}}%
      }
      \list{publisher}{2}{%
        {Springer Science}%
        {Business Media {LLC}}%
      }
      \strng{namehash}{2a6f8b4752df705b97d9f0452661fb9d}
      \strng{fullhash}{2a6f8b4752df705b97d9f0452661fb9d}
      \strng{bibnamehash}{2a6f8b4752df705b97d9f0452661fb9d}
      \strng{authorbibnamehash}{2a6f8b4752df705b97d9f0452661fb9d}
      \strng{authornamehash}{2a6f8b4752df705b97d9f0452661fb9d}
      \strng{authorfullhash}{2a6f8b4752df705b97d9f0452661fb9d}
      \field{sortinit}{6}
      \field{sortinithash}{57e57fb8451e7fcfa45d1e069f6d3136}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In recent years the development of computational techniques that build models to correctly assign chemical compounds to various classes or to retrieve potential drug-like compounds has been an active area of research. Many of the best-performing techniques for these tasks utilize a descriptor-based representation of the compound that captures various aspects of the underlying molecular graph's topology. In this paper we compare five different set of descriptors that are currently used for chemical compound classification. We also introduce four different descriptors derived from all connected fragments present in the molecular graphs primarily for the purpose of comparing them to the currently used descriptor spaces and analyzing what properties of descriptor spaces are helpful in providing effective representation for molecular graphs. In addition, we introduce an extension to existing vector-based kernel functions to take into account the length of the fragments present in the descriptors. We experimentally evaluate the performance of the previously introduced and the new descriptors in the context of SVM-based classification and ranked-retrieval on 28 classification and retrieval problems derived from 18 datasets. Our experiments show that for both of these tasks, two of the four descriptors introduced in this paper along with the extended connectivity fingerprint based descriptors consistently and statistically outperform previously developed schemes based on the widely used fingerprint-and Maccs keys-based descriptors, as well as recently introduced descriptors obtained by mining and analyzing the structure of the molecular graphs.}
      \field{day}{23}
      \field{journaltitle}{Knowledge and Information Systems}
      \field{month}{8}
      \field{number}{3}
      \field{title}{Comparison of descriptor spaces for chemical compound retrieval and classification}
      \field{volume}{14}
      \field{year}{2007}
      \field{dateera}{ce}
      \field{pages}{347\bibrangedash 375}
      \range{pages}{29}
      \verb{doi}
      \verb 10.1007/s10115-007-0103-5
      \endverb
      \verb{file}
      \verb :/home/fabrice/Documents/Uni/Literature/Papers/2007_Wale_CONF.pdf:PDF
      \endverb
      \verb{urlraw}
      \verb https://link.springer.com/article/10.1007/s10115-007-0103-5
      \endverb
      \verb{url}
      \verb https://link.springer.com/article/10.1007/s10115-007-0103-5
      \endverb
      \keyw{Classification,Retreival,Descriptor space,Kernel}
    \endentry
    \entry{2015_Yanardag_CONF}{inproceedings}{}
      \name{author}{2}{}{%
        {{hash=315230fe7fad7cc504b1310e995e9902}{%
           family={Yanardag},
           familyi={Y\bibinitperiod},
           given={Pinar},
           giveni={P\bibinitperiod}}}%
        {{hash=e8b108a34672d11328ea389ebc612976}{%
           family={Vishwanathan},
           familyi={V\bibinitperiod},
           given={S.\bibnamedelimi V.\bibnamedelimi N.},
           giveni={S\bibinitperiod\bibinitdelim V\bibinitperiod\bibinitdelim N\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {ACM}%
      }
      \strng{namehash}{93069d7add9a54965dee489dd1a5df30}
      \strng{fullhash}{93069d7add9a54965dee489dd1a5df30}
      \strng{bibnamehash}{93069d7add9a54965dee489dd1a5df30}
      \strng{authorbibnamehash}{93069d7add9a54965dee489dd1a5df30}
      \strng{authornamehash}{93069d7add9a54965dee489dd1a5df30}
      \strng{authorfullhash}{93069d7add9a54965dee489dd1a5df30}
      \field{sortinit}{6}
      \field{sortinithash}{57e57fb8451e7fcfa45d1e069f6d3136}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In this paper, we present Deep Graph Kernels, a unified framework to learn latent representations of sub-structures for graphs, inspired by latest advancements in language modeling and deep learning. Our framework leverages the dependency information between sub-structures by learning their latent representations. We demonstrate instances of our framework on three popular graph kernels, namely Graphlet kernels, Weisfeiler-Lehman subtree kernels, and Shortest-Path graph kernels. Our experiments on several benchmark datasets show that Deep Graph Kernels achieve significant improvements in classification accuracy over state-of-the-art graph kernels.}
      \field{booktitle}{Proceedings of the 21th {ACM} {SIGKDD} International Conference on Knowledge Discovery and Data Mining}
      \field{month}{8}
      \field{title}{Deep Graph Kernels}
      \field{year}{2015}
      \verb{doi}
      \verb 10.1145/2783258.2783417
      \endverb
      \verb{urlraw}
      \verb https://dl.acm.org/doi/10.1145/2783258.2783417
      \endverb
      \verb{url}
      \verb https://dl.acm.org/doi/10.1145/2783258.2783417
      \endverb
    \endentry
    \entry{2020_Siglidis_CONF}{inproceedings}{}
      \name{author}{6}{}{%
        {{hash=467858715fa2e97ced5fdfc67522ffe5}{%
           family={Siglidis},
           familyi={S\bibinitperiod},
           given={Giannis},
           giveni={G\bibinitperiod}}}%
        {{hash=d17f55fb1669e9c5047812134fd326fb}{%
           family={Nikolentzos},
           familyi={N\bibinitperiod},
           given={Giannis},
           giveni={G\bibinitperiod}}}%
        {{hash=f23c0379b1721b476c8b05a515d269b5}{%
           family={Limnios},
           familyi={L\bibinitperiod},
           given={Stratis},
           giveni={S\bibinitperiod}}}%
        {{hash=17a3d50aaa6a5312e4f668051c2d87a5}{%
           family={Giatsidis},
           familyi={G\bibinitperiod},
           given={Christos},
           giveni={C\bibinitperiod}}}%
        {{hash=a0b275498baa22c3a8715fbb5f2df110}{%
           family={Skianis},
           familyi={S\bibinitperiod},
           given={Konstantinos},
           giveni={K\bibinitperiod}}}%
        {{hash=a325a5cf58bcb9d372a4bcab568fc2c5}{%
           family={Vazirgiannis},
           familyi={V\bibinitperiod},
           given={Michalis},
           giveni={M\bibinitperiod}}}%
      }
      \name{editor}{1}{}{%
        {{hash=8e8a78a3239f1236bd6ca432104c6c7f}{%
           family={Honkela},
           familyi={H\bibinitperiod},
           given={Antti},
           giveni={A\bibinitperiod}}}%
      }
      \strng{namehash}{bf484ee237a9598e1782f800596d767e}
      \strng{fullhash}{22994458b92202d0fff7d4635116c680}
      \strng{bibnamehash}{bf484ee237a9598e1782f800596d767e}
      \strng{authorbibnamehash}{bf484ee237a9598e1782f800596d767e}
      \strng{authornamehash}{bf484ee237a9598e1782f800596d767e}
      \strng{authorfullhash}{22994458b92202d0fff7d4635116c680}
      \strng{editorbibnamehash}{8e8a78a3239f1236bd6ca432104c6c7f}
      \strng{editornamehash}{8e8a78a3239f1236bd6ca432104c6c7f}
      \strng{editorfullhash}{8e8a78a3239f1236bd6ca432104c6c7f}
      \field{sortinit}{6}
      \field{sortinithash}{57e57fb8451e7fcfa45d1e069f6d3136}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{The problem of accurately measuring the similarity between graphs is at the core of many applications in a variety of disciplines. Graph kernels have recently emerged as a promising approach to this problem. There are now many kernels, each focusing on different structural aspects of graphs. Here, we present GraKeL, a library that unifies several graph kernels into a common framework. The library is written in Python and adheres to the scikit-learn interface. It is simple to use and can be naturally combined with scikit-learn's modules to build a complete machine learning pipeline for tasks such as graph classification and clustering. The code is BSD licensed and is available at: https://github.com/ysig/ GraKeL.}
      \field{title}{GraKeL: A Graph Kernel Library in Python}
      \field{year}{2020}
      \verb{file}
      \verb :/home/fabrice/Documents/Uni/Literature/Papers/2020_Siglidis_JMLR.pdf:PDF
      \endverb
      \keyw{graph similarity,graph kernels,scikit-learn,Python}
    \endentry
    \entry{2020_Dwivedi_CONF}{inproceedings}{}
      \name{author}{5}{}{%
        {{hash=bc8fc15f38df261f071cf7520f3ac92b}{%
           family={Dwivedi},
           familyi={D\bibinitperiod},
           given={Vijay\bibnamedelima Prakash},
           giveni={V\bibinitperiod\bibinitdelim P\bibinitperiod}}}%
        {{hash=ab8c07cc3e4b75e109d02183ff3cf1c0}{%
           family={Joshi},
           familyi={J\bibinitperiod},
           given={Chaitanya\bibnamedelima K.},
           giveni={C\bibinitperiod\bibinitdelim K\bibinitperiod}}}%
        {{hash=d66f49f9b67b04f4f98b4d839f2af5e8}{%
           family={Laurent},
           familyi={L\bibinitperiod},
           given={Thomas},
           giveni={T\bibinitperiod}}}%
        {{hash=40a8e4774982146adc2688546f54efb2}{%
           family={Bengio},
           familyi={B\bibinitperiod},
           given={Yoshua},
           giveni={Y\bibinitperiod}}}%
        {{hash=26bf36a5046daec764f03647500c3871}{%
           family={Bresson},
           familyi={B\bibinitperiod},
           given={Xavier},
           giveni={X\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{77a4e5f881bb023e6f1560bd91302246}
      \strng{fullhash}{ade2fda7bf938540447b4634e4ce2cf8}
      \strng{bibnamehash}{77a4e5f881bb023e6f1560bd91302246}
      \strng{authorbibnamehash}{77a4e5f881bb023e6f1560bd91302246}
      \strng{authornamehash}{77a4e5f881bb023e6f1560bd91302246}
      \strng{authorfullhash}{ade2fda7bf938540447b4634e4ce2cf8}
      \field{sortinit}{6}
      \field{sortinithash}{57e57fb8451e7fcfa45d1e069f6d3136}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Graph neural networks (GNNs) have become the standard toolkit for analyzing and learning from data on graphs. As the field grows, it becomes critical to identify key architectures and validate new ideas that generalize to larger, more complex datasets. Unfortunately, it has been increasingly difficult to gauge the effectiveness of new models in the absence of a standardized benchmark with consistent experimental settings. In this paper, we introduce a reproducible GNN benchmarking framework, with the facility for researchers to add new models conveniently for arbitrary datasets. We demonstrate the usefulness of our framework by presenting a principled investigation into the recent Weisfeiler-Lehman GNNs (WL-GNNs) compared to message passing-based graph convolutional networks (GCNs) for a variety of graph tasks, i.e. graph regression/classification and node/link prediction, with medium-scale datasets.}
      \field{title}{Benchmarking Graph Neural Networks}
      \field{year}{2020}
      \verb{doi}
      \verb 10.48550/ARXIV.2003.00982
      \endverb
      \verb{file}
      \verb :2020_Dwivedi_CONF.pdf:PDF
      \endverb
      \verb{urlraw}
      \verb https://arxiv.org/abs/2003.00982
      \endverb
      \verb{url}
      \verb https://arxiv.org/abs/2003.00982
      \endverb
      \keyw{Machine Learning (cs.LG),Machine Learning (stat.ML),FOS: Computer and information sciences}
    \endentry
    \entry{2019_Schulz_CONF}{inproceedings}{}
      \name{author}{2}{}{%
        {{hash=d1ad67934f95efc64f297b7096dbde7a}{%
           family={Schulz},
           familyi={S\bibinitperiod},
           given={Till},
           giveni={T\bibinitperiod}}}%
        {{hash=60972706ebe48840b82ca646ffe3e72f}{%
           family={Welke},
           familyi={W\bibinitperiod},
           given={Pascal},
           giveni={P\bibinitperiod}}}%
      }
      \strng{namehash}{0aad62fcb3c5a87590bb59e0a1e6f0fb}
      \strng{fullhash}{0aad62fcb3c5a87590bb59e0a1e6f0fb}
      \strng{bibnamehash}{0aad62fcb3c5a87590bb59e0a1e6f0fb}
      \strng{authorbibnamehash}{0aad62fcb3c5a87590bb59e0a1e6f0fb}
      \strng{authornamehash}{0aad62fcb3c5a87590bb59e0a1e6f0fb}
      \strng{authorfullhash}{0aad62fcb3c5a87590bb59e0a1e6f0fb}
      \field{sortinit}{6}
      \field{sortinithash}{57e57fb8451e7fcfa45d1e069f6d3136}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Naturally, graph structured data is not easy to learn from. As opposed to itemsets which can be represented by a table of fixed length, there is no obvious representation language for graphs which allows for an easy similarity measure in order to perform e.g. classification tasks on sets of graphs. There have been introduced numerous graph kernels which tackle the problem of defining a suitable similarity between graphs by incorporating structural information. In this article, however, we revert to the very simplistic approach which is to regard a graph as a (multi- ) itemset made up of node and edge labels. We consider our method as a baseline and compare it to several established graph kernels on a wide range of benchmark datasets. Our observations suggest that for the overwhelming number of available datasets, actually utilizing the graphs’ structure in graph kernels does not significantly improve the classification accuracy.}
      \field{title}{On the Necessity of Graph Kernel Baselines}
      \field{year}{2019}
      \verb{file}
      \verb :/home/fabrice/Documents/Uni/Literature/Papers/2019_Schulz_CONF.pdf:PDF
      \endverb
      \verb{urlraw}
      \verb https://gem-ecmlpkdd.github.io/archive/2019/papers/GEM2019_paper_17.pdf
      \endverb
      \verb{url}
      \verb https://gem-ecmlpkdd.github.io/archive/2019/papers/GEM2019_paper_17.pdf
      \endverb
    \endentry
    \entry{2017_Welke_CONF}{article}{}
      \name{author}{3}{}{%
        {{hash=60972706ebe48840b82ca646ffe3e72f}{%
           family={Welke},
           familyi={W\bibinitperiod},
           given={Pascal},
           giveni={P\bibinitperiod}}}%
        {{hash=ac6c25478e2dce34e35e9cf93feac18d}{%
           family={Horv{á}th},
           familyi={H\bibinitperiod},
           given={Tam{á}s},
           giveni={T\bibinitperiod}}}%
        {{hash=9f8e62cad9a584bd2b54a6029652660f}{%
           family={Wrobel},
           familyi={W\bibinitperiod},
           given={Stefan},
           giveni={S\bibinitperiod}}}%
      }
      \list{publisher}{2}{%
        {Springer Science}%
        {Business Media {LLC}}%
      }
      \strng{namehash}{e4cb45a28d0af4a552241f9bab3fa44f}
      \strng{fullhash}{e4cb45a28d0af4a552241f9bab3fa44f}
      \strng{bibnamehash}{e4cb45a28d0af4a552241f9bab3fa44f}
      \strng{authorbibnamehash}{e4cb45a28d0af4a552241f9bab3fa44f}
      \strng{authornamehash}{e4cb45a28d0af4a552241f9bab3fa44f}
      \strng{authorfullhash}{e4cb45a28d0af4a552241f9bab3fa44f}
      \field{sortinit}{6}
      \field{sortinithash}{57e57fb8451e7fcfa45d1e069f6d3136}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Frequent subgraphs proved to be powerful features for graph classification and prediction tasks. Their practical use is, however, limited by the computational intractability of pattern enumeration and that of graph embedding into frequent subgraph feature spaces. We propose a simple probabilistic technique that resolves both limitations. In particular, we restrict the pattern language to trees and relax the demand on the completeness of the mining algorithm, as well as on the correctness of the pattern matching operator by replacing transaction and query graphs with small random samples of their spanning trees. In this way we consider only a random subset of frequent subtrees, called probabilistic frequent subtrees, that can be enumerated efficiently. Our extensive empirical evaluation on artificial and benchmark molecular graph datasets shows that probabilistic frequent subtrees can be listed in practically feasible time and that their predictive and retrieval performance is very close even to those of complete sets of frequent subgraphs. We also present different fast techniques for computing the embedding of unseen graphs into (probabilistic frequent) subtree feature spaces. These algorithms utilize the partial order on tree patterns induced by subgraph isomorphism and, as we show empirically, require much less evaluations of subtree isomorphism than the standard brute-force algorithm. We also consider partial embeddings, i.e., when only a part of the feature vector has to be calculated. In particular, we propose a highly effective practical algorithm that significantly reduces the number of pattern matching evaluations required by the classical min-hashing algorithm approximating Jaccard-similarities.}
      \field{journaltitle}{Machine Learning}
      \field{month}{11}
      \field{number}{11}
      \field{title}{Probabilistic frequent subtrees for efficient graph classification and retrieval}
      \field{volume}{107}
      \field{year}{2017}
      \field{pages}{1847\bibrangedash 1873}
      \range{pages}{27}
      \verb{doi}
      \verb 10.1007/s10994-017-5688-7
      \endverb
      \verb{file}
      \verb :2017_Welke_CONF.pdf:PDF
      \endverb
      \verb{urlraw}
      \verb https://link.springer.com/article/10.1007/s10994-017-5688-7
      \endverb
      \verb{url}
      \verb https://link.springer.com/article/10.1007/s10994-017-5688-7
      \endverb
    \endentry
    \entry{2009_Scarselli_IEEE}{article}{}
      \name{author}{5}{}{%
        {{hash=f7c38a09df003370034d067b453ad07b}{%
           family={Scarselli},
           familyi={S\bibinitperiod},
           given={F.},
           giveni={F\bibinitperiod}}}%
        {{hash=24a6f526bae1303a16c25a75df57f22b}{%
           family={Gori},
           familyi={G\bibinitperiod},
           given={M.},
           giveni={M\bibinitperiod}}}%
        {{hash=bad8c3458d4ad9db77a764f7bfaed629}{%
           family={Tsoi},
           familyi={T\bibinitperiod},
           given={Ah\bibnamedelima Chung},
           giveni={A\bibinitperiod\bibinitdelim C\bibinitperiod}}}%
        {{hash=cc44ab6ee97a1298e82394ad1a519984}{%
           family={Hagenbuchner},
           familyi={H\bibinitperiod},
           given={M.},
           giveni={M\bibinitperiod}}}%
        {{hash=965d2ea546cbb427e96d4041c80a49db}{%
           family={Monfardini},
           familyi={M\bibinitperiod},
           given={G.},
           giveni={G\bibinitperiod}}}%
      }
      \list{publisher}{2}{%
        {Institute of Electrical}%
        {Electronics Engineers ({IEEE})}%
      }
      \strng{namehash}{38922e900e0ff1815549365d6b706f15}
      \strng{fullhash}{8ae455bd01a6ad871b8357dc8757989c}
      \strng{bibnamehash}{38922e900e0ff1815549365d6b706f15}
      \strng{authorbibnamehash}{38922e900e0ff1815549365d6b706f15}
      \strng{authornamehash}{38922e900e0ff1815549365d6b706f15}
      \strng{authorfullhash}{8ae455bd01a6ad871b8357dc8757989c}
      \field{sortinit}{7}
      \field{sortinithash}{c818dd9105a2852444fc9f5e145c294e}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Many underlying relationships among data in several areas of science and engineering, e.g., computer vision, molecular chemistry, molecular biology, pattern recognition, and data mining, can be represented in terms of graphs. In this paper, we propose a new neural network model, called graph neural network (GNN) model, that extends existing neural network methods for processing the data represented in graph domains. This GNN model, which can directly process most of the practically useful types of graphs, e.g., acyclic, cyclic, directed, and undirected, implements a function tau(G,n) isin IR m that maps a graph G and one of its nodes n into an m -dimensional Euclidean space. A supervised learning algorithm is derived to estimate the parameters of the proposed GNN model. The computational cost of the proposed algorithm is also considered. Some experimental results are shown to validate the proposed learning algorithm, and to demonstrate its generalization capabilities.}
      \field{journaltitle}{{IEEE} Transactions on Neural Networks}
      \field{month}{1}
      \field{number}{1}
      \field{title}{The Graph Neural Network Model}
      \field{volume}{20}
      \field{year}{2009}
      \field{pages}{61\bibrangedash 80}
      \range{pages}{20}
      \verb{doi}
      \verb 10.1109/tnn.2008.2005605
      \endverb
      \verb{file}
      \verb :2009_Scarselli_IEEE.pdf:PDF
      \endverb
      \verb{urlraw}
      \verb https://ieeexplore.ieee.org/abstract/document/4700287
      \endverb
      \verb{url}
      \verb https://ieeexplore.ieee.org/abstract/document/4700287
      \endverb
    \endentry
    \entry{2019_Xu_CONF}{inproceedings}{}
      \name{author}{4}{}{%
        {{hash=29a3a6bf823a641230b0258e0a8a0214}{%
           family={Xu},
           familyi={X\bibinitperiod},
           given={Keyulu},
           giveni={K\bibinitperiod}}}%
        {{hash=164c7f22cde069c57bf9b80f76441fa9}{%
           family={Hu},
           familyi={H\bibinitperiod},
           given={Weihua},
           giveni={W\bibinitperiod}}}%
        {{hash=900d107125ff0ca84698cb909e4f6c51}{%
           family={Leskovec},
           familyi={L\bibinitperiod},
           given={Jure},
           giveni={J\bibinitperiod}}}%
        {{hash=83a44c18acfaa38fa9f6ba76cfdc0132}{%
           family={Jegelka},
           familyi={J\bibinitperiod},
           given={Stefanie},
           giveni={S\bibinitperiod}}}%
      }
      \strng{namehash}{a2fd7b685ef3372c1078c0dcfad82a73}
      \strng{fullhash}{3fe1c2e12a449ac359ab2737dfe4ce17}
      \strng{bibnamehash}{a2fd7b685ef3372c1078c0dcfad82a73}
      \strng{authorbibnamehash}{a2fd7b685ef3372c1078c0dcfad82a73}
      \strng{authornamehash}{a2fd7b685ef3372c1078c0dcfad82a73}
      \strng{authorfullhash}{3fe1c2e12a449ac359ab2737dfe4ce17}
      \field{sortinit}{7}
      \field{sortinithash}{c818dd9105a2852444fc9f5e145c294e}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Graph Neural Networks (GNNs) are an effective framework for representation learning of graphs. GNNs follow a neighborhood aggregation scheme, where the representation vector of a node is computed by recursively aggregating and transforming representation vectors of its neighboring nodes. Many GNN variants have been proposed and have achieved state-of-the-art results on both node and graph classification tasks. However, despite GNNs revolutionizing graph representation learning, there is limited understanding of their representational properties and limitations. Here, we present a theoretical framework for analyzing the expressive power of GNNs to capture different graph structures. Our results characterize the discriminative power of popular GNN variants, such as Graph Convolutional Networks and GraphSAGE, and show that they cannot learn to distinguish certain simple graph structures. We then develop a simple architecture that is provably the most expressive among the class of GNNs and is as powerful as the Weisfeiler-Lehman graph isomorphism test. We empirically validate our theoretical findings on a number of graph classification benchmarks, and demonstrate that our model achieves state-of-the-art performance.}
      \field{booktitle}{International Conference on Learning Representations}
      \field{title}{{HOW POWERFULARE GRAPH NEURAL NETWORKS?}}
      \field{year}{2019}
      \verb{file}
      \verb :/home/fabrice/Documents/Uni/Literature/Papers/2019_Xu_CONF.pdf:PDF
      \endverb
      \verb{urlraw}
      \verb https://arxiv.org/abs/1810.00826
      \endverb
      \verb{url}
      \verb https://arxiv.org/abs/1810.00826
      \endverb
    \endentry
    \entry{2017_Velickovic_ICLR}{inproceedings}{}
      \name{author}{6}{}{%
        {{hash=b1208a71c9b067bcef8fb29c15a09b5d}{%
           family={Veličković},
           familyi={V\bibinitperiod},
           given={Petar},
           giveni={P\bibinitperiod}}}%
        {{hash=c30bc5878e196747275a7ff581c6ed22}{%
           family={Cucurull},
           familyi={C\bibinitperiod},
           given={Guillem},
           giveni={G\bibinitperiod}}}%
        {{hash=5a0765951987db22af274a31732111fa}{%
           family={Casanova},
           familyi={C\bibinitperiod},
           given={Arantxa},
           giveni={A\bibinitperiod}}}%
        {{hash=8e0f06556535de7b7d9d04d390dc4ac3}{%
           family={Romero},
           familyi={R\bibinitperiod},
           given={Adriana},
           giveni={A\bibinitperiod}}}%
        {{hash=b1dc447055a5e64105a2984bf8306851}{%
           family={Liò},
           familyi={L\bibinitperiod},
           given={Pietro},
           giveni={P\bibinitperiod}}}%
        {{hash=40a8e4774982146adc2688546f54efb2}{%
           family={Bengio},
           familyi={B\bibinitperiod},
           given={Yoshua},
           giveni={Y\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{80ab98f127e70d48b7af0b2df2615846}
      \strng{fullhash}{e36c8bf9f36dc60726c1c2afa402755c}
      \strng{bibnamehash}{80ab98f127e70d48b7af0b2df2615846}
      \strng{authorbibnamehash}{80ab98f127e70d48b7af0b2df2615846}
      \strng{authornamehash}{80ab98f127e70d48b7af0b2df2615846}
      \strng{authorfullhash}{e36c8bf9f36dc60726c1c2afa402755c}
      \field{sortinit}{7}
      \field{sortinithash}{c818dd9105a2852444fc9f5e145c294e}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We present graph attention networks (GATs), novel neural network architectures that operate on graph-structured data, leveraging masked self-attentional layers to address the shortcomings of prior methods based on graph convolutions or their approximations. By stacking layers in which nodes are able to attend over their neighborhoods' features, we enable (implicitly) specifying different weights to different nodes in a neighborhood, without requiring any kind of costly matrix operation (such as inversion) or depending on knowing the graph structure upfront. In this way, we address several key challenges of spectral-based graph neural networks simultaneously, and make our model readily applicable to inductive as well as transductive problems. Our GAT models have achieved or matched state-of-the-art results across four established transductive and inductive graph benchmarks: the Cora, Citeseer and Pubmed citation network datasets, as well as a protein-protein interaction dataset (wherein test graphs remain unseen during training).}
      \field{title}{Graph Attention Networks}
      \field{year}{2017}
      \verb{doi}
      \verb 10.48550/ARXIV.1710.10903
      \endverb
      \verb{file}
      \verb :2017_Velickovic_ICLR.pdf:PDF
      \endverb
      \verb{urlraw}
      \verb https://arxiv.org/abs/1710.10903
      \endverb
      \verb{url}
      \verb https://arxiv.org/abs/1710.10903
      \endverb
      \keyw{Machine Learning (stat.ML),Artificial Intelligence (cs.AI),Machine Learning (cs.LG),Social and Information Networks (cs.SI),FOS: Computer and information sciences}
    \endentry
    \entry{2016_Cheng_CONF}{misc}{}
      \name{author}{3}{}{%
        {{hash=ea420c999bde7b92905ea4ce7147ec31}{%
           family={Cheng},
           familyi={C\bibinitperiod},
           given={Jianpeng},
           giveni={J\bibinitperiod}}}%
        {{hash=d3349e5c2b2661f3b497e9f014ffcf7d}{%
           family={Dong},
           familyi={D\bibinitperiod},
           given={Li},
           giveni={L\bibinitperiod}}}%
        {{hash=35b5bc53ec3fa2640225354af6ca0e1d}{%
           family={Lapata},
           familyi={L\bibinitperiod},
           given={Mirella},
           giveni={M\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{236823a84e8a9876ff9cd5376cf85940}
      \strng{fullhash}{236823a84e8a9876ff9cd5376cf85940}
      \strng{bibnamehash}{236823a84e8a9876ff9cd5376cf85940}
      \strng{authorbibnamehash}{236823a84e8a9876ff9cd5376cf85940}
      \strng{authornamehash}{236823a84e8a9876ff9cd5376cf85940}
      \strng{authorfullhash}{236823a84e8a9876ff9cd5376cf85940}
      \field{sortinit}{7}
      \field{sortinithash}{c818dd9105a2852444fc9f5e145c294e}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{title}{Long Short-Term Memory-Networks for Machine Reading}
      \field{year}{2016}
      \verb{doi}
      \verb 10.48550/ARXIV.1601.06733
      \endverb
      \keyw{Computation and Language (cs.CL),Neural and Evolutionary Computing (cs.NE),FOS: Computer and information sciences}
    \endentry
    \entry{2018_Korte_BOOK}{book}{}
      \name{author}{2}{}{%
        {{hash=54f9857605c0ba40b057d6545ee51cca}{%
           family={Korte},
           familyi={K\bibinitperiod},
           given={Bernhard},
           giveni={B\bibinitperiod}}}%
        {{hash=60b91c18a457236628f65ee35ab35ddb}{%
           family={Vygen},
           familyi={V\bibinitperiod},
           given={Jens},
           giveni={J\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Springer Berlin Heidelberg}%
      }
      \strng{namehash}{1d60ca392602bfae2d949aa92b576f85}
      \strng{fullhash}{1d60ca392602bfae2d949aa92b576f85}
      \strng{bibnamehash}{1d60ca392602bfae2d949aa92b576f85}
      \strng{authorbibnamehash}{1d60ca392602bfae2d949aa92b576f85}
      \strng{authornamehash}{1d60ca392602bfae2d949aa92b576f85}
      \strng{authorfullhash}{1d60ca392602bfae2d949aa92b576f85}
      \field{sortinit}{8}
      \field{sortinithash}{07edf88d4ea82509b9c4b4d13f41c452}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{title}{Combinatorial Optimization}
      \field{year}{2018}
      \verb{doi}
      \verb 10.1007/978-3-662-56039-6
      \endverb
      \verb{file}
      \verb :2018_Korte_BOOK - Combinatorial Optimization.pdf:PDF
      \endverb
    \endentry
    \entry{2019_Le_NIPS}{inproceedings}{}
      \name{author}{4}{}{%
        {{hash=ae32f3e9387060fcf301c2a9cbba54cd}{%
           family={Le},
           familyi={L\bibinitperiod},
           given={Tam},
           giveni={T\bibinitperiod}}}%
        {{hash=3b119bb2694b8f8d231b806ab8229549}{%
           family={Yamada},
           familyi={Y\bibinitperiod},
           given={Makoto},
           giveni={M\bibinitperiod}}}%
        {{hash=e9c11e7f6e771dbb75fdfa98f94e91a0}{%
           family={Fukumizu},
           familyi={F\bibinitperiod},
           given={Kenji},
           giveni={K\bibinitperiod}}}%
        {{hash=a771427291cb72a39e026a68b102335d}{%
           family={Cuturi},
           familyi={C\bibinitperiod},
           given={Marco},
           giveni={M\bibinitperiod}}}%
      }
      \strng{namehash}{eab4a80a2891a86aa6ea1ac9b2cdf236}
      \strng{fullhash}{be5aa53766fc9eabcec6744a64715d28}
      \strng{bibnamehash}{eab4a80a2891a86aa6ea1ac9b2cdf236}
      \strng{authorbibnamehash}{eab4a80a2891a86aa6ea1ac9b2cdf236}
      \strng{authornamehash}{eab4a80a2891a86aa6ea1ac9b2cdf236}
      \strng{authorfullhash}{be5aa53766fc9eabcec6744a64715d28}
      \field{sortinit}{8}
      \field{sortinithash}{07edf88d4ea82509b9c4b4d13f41c452}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Optimal transport (OT) theory defines a powerful set of tools to compare probability distributions. OT suffers however from a few drawbacks, computational and statistical, which have encouraged the proposal of several regularized variants of OT in the recent literature, one of the most notable being the sliced formulation, which exploits the closed-form formula between univariate distributions by projecting high-dimensional measures onto random lines. We consider in this work a more general family of ground metrics, namely tree metrics, which also yield fast closed-form computations and negative definite, and of which the sliced-Wasserstein distance is a particular case (the tree is a chain). We propose the tree-sliced Wasserstein distance, computed by averaging the Wasserstein distance between these measures using random tree metrics, built adaptively in either low or high-dimensional spaces. Exploiting the negative definiteness of that distance, we also propose a positive definite kernel, and test it against other baselines on a few benchmark tasks.}
      \field{booktitle}{Advances in Neural Information Processing Systems 32 (NeurIPS 2019)}
      \field{title}{Tree-Sliced Variants of Wasserstein Distances}
      \field{year}{2019}
      \verb{file}
      \verb :/home/fabrice/Documents/Uni/Literature/Papers/2019_Le_NIPS.pdf:PDF
      \endverb
      \verb{urlraw}
      \verb https://proceedings.neurips.cc/paper/2019/hash/2d36b5821f8affc6868b59dfc9af6c9f-Abstract.html
      \endverb
      \verb{url}
      \verb https://proceedings.neurips.cc/paper/2019/hash/2d36b5821f8affc6868b59dfc9af6c9f-Abstract.html
      \endverb
    \endentry
    \entry{2019_Maretic_CONF}{inproceedings}{}
      \name{author}{7}{}{%
        {{hash=4ef540e87efb9e96ade685d99959bc49}{%
           family={Maretic},
           familyi={M\bibinitperiod},
           given={Hermina\bibnamedelima Petric},
           giveni={H\bibinitperiod\bibinitdelim P\bibinitperiod}}}%
        {{hash=b2a8b96361b27ae5222f1c944709165d}{%
           family={Gheche},
           familyi={G\bibinitperiod},
           given={Mireille\bibnamedelima El},
           giveni={M\bibinitperiod\bibinitdelim E\bibinitperiod}}}%
        {{hash=e399fcfc3d453b7fd0b0182cacb56f8f}{%
           family={Chierchia},
           familyi={C\bibinitperiod},
           given={Giovanni},
           giveni={G\bibinitperiod}}}%
        {{hash=e518bde0346ee0137918fe68fd1f059f}{%
           family={Maretic},
           familyi={M\bibinitperiod},
           given={Pascal\bibnamedelimb FrossardHermina\bibnamedelima Petric},
           giveni={P\bibinitperiod\bibinitdelim F\bibinitperiod\bibinitdelim P\bibinitperiod}}}%
        {{hash=b2a8b96361b27ae5222f1c944709165d}{%
           family={Gheche},
           familyi={G\bibinitperiod},
           given={Mireille\bibnamedelima El},
           giveni={M\bibinitperiod\bibinitdelim E\bibinitperiod}}}%
        {{hash=e399fcfc3d453b7fd0b0182cacb56f8f}{%
           family={Chierchia},
           familyi={C\bibinitperiod},
           given={Giovanni},
           giveni={G\bibinitperiod}}}%
        {{hash=e3ffdb452de6d0eeff420ceb94f14446}{%
           family={Frossard},
           familyi={F\bibinitperiod},
           given={Pascal},
           giveni={P\bibinitperiod}}}%
      }
      \strng{namehash}{b135a2caea18732d78ce1c9bd3b3e9cf}
      \strng{fullhash}{02da5ade222fee4d22d7175882a3bf77}
      \strng{bibnamehash}{b135a2caea18732d78ce1c9bd3b3e9cf}
      \strng{authorbibnamehash}{b135a2caea18732d78ce1c9bd3b3e9cf}
      \strng{authornamehash}{b135a2caea18732d78ce1c9bd3b3e9cf}
      \strng{authorfullhash}{02da5ade222fee4d22d7175882a3bf77}
      \field{sortinit}{8}
      \field{sortinithash}{07edf88d4ea82509b9c4b4d13f41c452}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We present a novel framework based on optimal transport for the challenging problem of comparing graphs. Specifically, we exploit the probabilistic distribution of smooth graph signals defined with respect to the graph topology. This allows us to derive an explicit expression of the Wasserstein distance between graph signal distributions in terms of the graph Laplacian matrices. This leads to a structurally meaningful measure for comparing graphs, which is able to take into account the global structure of graphs, while most other measures merely observe local changes independently. Our measure is then used for formulating a new graph alignment problem, whose objective is to estimate the permutation that minimizes the distance between two graphs. We further propose an efficient stochastic algorithm based on Bayesian exploration to accommodate for the non-convexity of the graph alignment problem. We finally demonstrate the performance of our novel framework on different tasks like graph alignment, graph classification and graph signal prediction, and we show that our method leads to significant improvement with respect to the-state-of-art algorithms.}
      \field{booktitle}{Advances in Neural Information Processing Systems 32 (NeurIPS 2019)}
      \field{title}{{GOT}: An Optimal Transport framework for Graph comparison}
      \field{year}{2019}
      \verb{file}
      \verb :/home/fabrice/Documents/Uni/Literature/Papers/2019_Maretic_CONF.pdf:PDF
      \endverb
      \verb{urlraw}
      \verb https://proceedings.neurips.cc/paper/2019/hash/fdd5b16fc8134339089ef25b3cf0e588-Abstract.html
      \endverb
      \verb{url}
      \verb https://proceedings.neurips.cc/paper/2019/hash/fdd5b16fc8134339089ef25b3cf0e588-Abstract.html
      \endverb
    \endentry
    \entry{1781_Monge_CITATION}{article}{}
      \name{author}{1}{}{%
        {{hash=06f4f3a66ade015a1425e64f9c2d1cbb}{%
           family={Monge},
           familyi={M\bibinitperiod},
           given={Gaspard},
           giveni={G\bibinitperiod}}}%
      }
      \strng{namehash}{06f4f3a66ade015a1425e64f9c2d1cbb}
      \strng{fullhash}{06f4f3a66ade015a1425e64f9c2d1cbb}
      \strng{bibnamehash}{06f4f3a66ade015a1425e64f9c2d1cbb}
      \strng{authorbibnamehash}{06f4f3a66ade015a1425e64f9c2d1cbb}
      \strng{authornamehash}{06f4f3a66ade015a1425e64f9c2d1cbb}
      \strng{authorfullhash}{06f4f3a66ade015a1425e64f9c2d1cbb}
      \field{sortinit}{8}
      \field{sortinithash}{07edf88d4ea82509b9c4b4d13f41c452}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{Histoire de l'Acad{é}mie Royale des Sciences de Paris}
      \field{title}{M{é}moire sur la th{é}orie des d{é}blais et des remblais}
      \field{year}{1781}
    \endentry
    \entry{1942_Kantorovich_CITATION}{article}{}
      \name{author}{1}{}{%
        {{hash=4729e184f26d9343c2cab03511329e10}{%
           family={Kantorovich},
           familyi={K\bibinitperiod},
           given={Leonid\bibnamedelima Vitaliyevich},
           giveni={L\bibinitperiod\bibinitdelim V\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Akademiia Nauk Sssr}%
      }
      \strng{namehash}{4729e184f26d9343c2cab03511329e10}
      \strng{fullhash}{4729e184f26d9343c2cab03511329e10}
      \strng{bibnamehash}{4729e184f26d9343c2cab03511329e10}
      \strng{authorbibnamehash}{4729e184f26d9343c2cab03511329e10}
      \strng{authornamehash}{4729e184f26d9343c2cab03511329e10}
      \strng{authorfullhash}{4729e184f26d9343c2cab03511329e10}
      \field{sortinit}{8}
      \field{sortinithash}{07edf88d4ea82509b9c4b4d13f41c452}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{Doklady Akademii nauk USSR}
      \field{title}{On the transfer of masses}
      \field{year}{1942}
      \field{pages}{227\bibrangedash 229}
      \range{pages}{3}
    \endentry
    \entry{2019_Peyre}{article}{}
      \name{author}{2}{}{%
        {{hash=4798078c2412df12d901dd2b00667862}{%
           family={Peyr{é}},
           familyi={P\bibinitperiod},
           given={Gabriel},
           giveni={G\bibinitperiod}}}%
        {{hash=a771427291cb72a39e026a68b102335d}{%
           family={Cuturi},
           familyi={C\bibinitperiod},
           given={Marco},
           giveni={M\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Now Publishers}%
      }
      \strng{namehash}{45f2a9db48930735c038adda69395375}
      \strng{fullhash}{45f2a9db48930735c038adda69395375}
      \strng{bibnamehash}{45f2a9db48930735c038adda69395375}
      \strng{authorbibnamehash}{45f2a9db48930735c038adda69395375}
      \strng{authornamehash}{45f2a9db48930735c038adda69395375}
      \strng{authorfullhash}{45f2a9db48930735c038adda69395375}
      \field{sortinit}{9}
      \field{sortinithash}{1dd72ab054147731c9d824b49aba0534}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Optimal transport (OT) theory can be informally described using the words of the French mathematician Gaspard Monge (1746–1818): A worker with a shovel in hand has to move a large pile of sand lying on a construction site. The goal of the worker is to erect with all that sand a target pile with a prescribed shape (for example, that of a giant sand castle). Naturally, the worker wishes to minimize her total effort, quantified for instance as the total distance or time spent carrying shovelfuls of sand. Mathematicians interested in OT cast that problem as that of comparing two probability distributions—two different piles of sand of the same volume. They consider all of the many possible ways to morph, transport or reshape the first pile into the second, and associate a “global” cost to every such transport, using the “local” consideration of how much it costs to move a grain of sand from one place to another. Mathematicians are interested in the properties of that least costly transport, as well as in its efficient computation. That smallest cost not only defines a distance between distributions, but it also entails a rich geometric structure on the space of probability distributions. That structure is canonical in the sense that it borrows key geometric properties of the underlying “ground” space on which these distributions are defined. For instance, when the underlying space is Euclidean, key concepts such as interpolation, barycenters, convexity or gradients of functions extend naturally to the space of distributions endowed with an OT geometry. OT has been (re)discovered in many settings and under different forms, giving it a rich history. While Monge’s seminal work was motivated by an engineering problem, Tolstoi in the 1920s and Hitchcock, Kantorovich and Koopmans in the 1940s established its significance to logistics and economics. Dantzig solved it numerically in 1949 within the framework of linear programming, giving OT a firm footing in optimization. OT was later revisited by analysts in the 1990s, notably Brenier, while also gaining fame in computer vision under the name of earth mover’s distances. Recent years have witnessed yet another revolution in the spread of OT, thanks to the emergence of approximate solvers that can scale to large problem dimensions. As a consequence, OT is being increasingly used to unlock various problems in imaging sciences (such as color or texture processing), graphics (for shape manipulation) or machine learning (for regression, classification and generative modeling). This paper reviews OT with a bias toward numerical methods, and covers the theoretical properties of OT that can guide the design of new algorithms.We focus in particular on the recent wave of efficient algorithms that have helped OT find relevance in data sciences. We give a prominent place to the many generalizations of OT that have been proposed in but a few years, and connect them with related approaches originating from statistical inference, kernel methods and information theory. All of the figures can be reproduced using code made available on a companion website. This website hosts the book project Computational Optimal Transport. You will also find slides and computational resources.}
      \field{journaltitle}{Foundations and Trends{®} in Machine Learning}
      \field{number}{5-6}
      \field{title}{Computational Optimal Transport: With Applications to Data Science}
      \field{volume}{11}
      \field{year}{2019}
      \field{pages}{355\bibrangedash 607}
      \range{pages}{253}
      \verb{doi}
      \verb 10.1561/2200000073
      \endverb
    \endentry
    \entry{2009_Villani_BOOK}{book}{}
      \name{author}{1}{}{%
        {{hash=5b13aef3728e435f17a17ebcd55bd2e5}{%
           family={Villani},
           familyi={V\bibinitperiod},
           given={C{é}dric},
           giveni={C\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Springer}%
      }
      \strng{namehash}{5b13aef3728e435f17a17ebcd55bd2e5}
      \strng{fullhash}{5b13aef3728e435f17a17ebcd55bd2e5}
      \strng{bibnamehash}{5b13aef3728e435f17a17ebcd55bd2e5}
      \strng{authorbibnamehash}{5b13aef3728e435f17a17ebcd55bd2e5}
      \strng{authornamehash}{5b13aef3728e435f17a17ebcd55bd2e5}
      \strng{authorfullhash}{5b13aef3728e435f17a17ebcd55bd2e5}
      \field{sortinit}{9}
      \field{sortinithash}{1dd72ab054147731c9d824b49aba0534}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{title}{Optimal transport: old and new}
      \field{volume}{338}
      \field{year}{2009}
    \endentry
    \entry{1999_Burkard_CONF}{incollection}{}
      \name{author}{2}{}{%
        {{hash=dac879f2e63badcba41d77a4c4cd44b7}{%
           family={Burkard},
           familyi={B\bibinitperiod},
           given={Rainer\bibnamedelima E.},
           giveni={R\bibinitperiod\bibinitdelim E\bibinitperiod}}}%
        {{hash=d428bec87b484f8b8944004117c07297}{%
           family={{Ç}ela},
           familyi={Ç\bibinitperiod},
           given={Eranda},
           giveni={E\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Springer {US}}%
      }
      \strng{namehash}{2a5e168ec519336c96ceee3a62df60bf}
      \strng{fullhash}{2a5e168ec519336c96ceee3a62df60bf}
      \strng{bibnamehash}{2a5e168ec519336c96ceee3a62df60bf}
      \strng{authorbibnamehash}{2a5e168ec519336c96ceee3a62df60bf}
      \strng{authornamehash}{2a5e168ec519336c96ceee3a62df60bf}
      \strng{authorfullhash}{2a5e168ec519336c96ceee3a62df60bf}
      \field{sortinit}{9}
      \field{sortinithash}{1dd72ab054147731c9d824b49aba0534}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{Handbook of Combinatorial Optimization}
      \field{title}{Linear Assignment Problems and Extensions}
      \field{year}{1999}
      \field{pages}{75\bibrangedash 149}
      \range{pages}{75}
      \verb{doi}
      \verb 10.1007/978-1-4757-3023-4_2
      \endverb
    \endentry
    \entry{1968_Weisfeiler_CONF}{inproceedings}{}
      \name{author}{2}{}{%
        {{hash=d32a392b4803435ca65a032183bf8e05}{%
           family={Weisfeiler},
           familyi={W\bibinitperiod}}}%
        {{hash=60018fbf037c3daef548df290f6696c8}{%
           family={Leman},
           familyi={L\bibinitperiod}}}%
      }
      \strng{namehash}{f159aedfd17b4d62ed2562fc90328519}
      \strng{fullhash}{f159aedfd17b4d62ed2562fc90328519}
      \strng{bibnamehash}{f159aedfd17b4d62ed2562fc90328519}
      \strng{authorbibnamehash}{f159aedfd17b4d62ed2562fc90328519}
      \strng{authornamehash}{f159aedfd17b4d62ed2562fc90328519}
      \strng{authorfullhash}{f159aedfd17b4d62ed2562fc90328519}
      \field{sortinit}{1}
      \field{sortinithash}{2174f786c6195e7fe2ee1c229b416e29}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We consider an algorithm for the reduction of a given finite multigraph Γ to canonical form. Therein the new invariant of a graph appears — the algebra A(Γ). The study of properties of the algebra A(Γ) turns out to be helpful in solving a number of graph-theoretic problems. We pose and discuss some conjectures on the relation between properties of the algebra A(Γ) and the automorphism group Aut(Γ) of a graph Γ. We give an example of undirected graph Γ whose algebra A(Γ) coincides with the group algebra of some noncommutative group.}
      \field{booktitle}{Journal of Applied Mathematics and Physics}
      \field{title}{{THE REDUCTION OF A GRAPH TO CANONICAL FORM AND THEALGEBRA WHICH APPEARS THEREIN}}
      \field{year}{1968}
      \verb{file}
      \verb :/home/fabrice/Documents/Uni/Literature/Papers/1968_Weisfeiler_CONF.pdf:PDF
      \endverb
    \endentry
    \entry{1992_Cai_IEEE}{inproceedings}{}
      \name{author}{3}{}{%
        {{hash=0986614777020a219c83d7d0f3d1e5ea}{%
           family={Cai},
           familyi={C\bibinitperiod},
           given={J.-Y.},
           giveni={J\bibinithyphendelim Y\bibinitperiod}}}%
        {{hash=3557184a38d30fec1f3afca219fa796d}{%
           family={Furer},
           familyi={F\bibinitperiod},
           given={M.},
           giveni={M\bibinitperiod}}}%
        {{hash=95bb235294868c59b0d9075442e00f5a}{%
           family={Immerman},
           familyi={I\bibinitperiod},
           given={N.},
           giveni={N\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {IEEE}%
      }
      \strng{namehash}{d663db4faa3683712f43522a6081ab87}
      \strng{fullhash}{d663db4faa3683712f43522a6081ab87}
      \strng{bibnamehash}{d663db4faa3683712f43522a6081ab87}
      \strng{authorbibnamehash}{d663db4faa3683712f43522a6081ab87}
      \strng{authornamehash}{d663db4faa3683712f43522a6081ab87}
      \strng{authorfullhash}{d663db4faa3683712f43522a6081ab87}
      \field{sortinit}{1}
      \field{sortinithash}{2174f786c6195e7fe2ee1c229b416e29}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{It is shown that Omega (n) variables are needed for first-order logic with counting to identify graphs on n vertices. This settles a long-standing open problem. The lower bound remains true over a set of graphs of color class size 4. This contrasts sharply with the fact that three variables suffice to identify all graphs of color class size 3, and two variables suffice to identify almost all graphs. The lower bound is optimal up to multiplication by a constant because n variables obviously suffice to identify graphs on n vertices.}
      \field{booktitle}{30th Annual Symposium on Foundations of Computer Science}
      \field{title}{An optimal lower bound on the number of variables for graph identification}
      \field{year}{1992}
      \verb{doi}
      \verb 10.1109/sfcs.1989.63543
      \endverb
      \verb{file}
      \verb :1992_Cai_IEEE.pdf:PDF
      \endverb
      \verb{urlraw}
      \verb https://ieeexplore.ieee.org/document/63543
      \endverb
      \verb{url}
      \verb https://ieeexplore.ieee.org/document/63543
      \endverb
    \endentry
    \entry{1979_Babai_CONF}{inproceedings}{}
      \name{author}{2}{}{%
        {{hash=4e1c541d57331357e60e841e3b48709b}{%
           family={Babai},
           familyi={B\bibinitperiod},
           given={Laszlo},
           giveni={L\bibinitperiod}}}%
        {{hash=3e475fbde1128b2712697695709c50fd}{%
           family={Kucera},
           familyi={K\bibinitperiod},
           given={Ludik},
           giveni={L\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {IEEE}%
      }
      \strng{namehash}{fb687e60b5c9a78610ecb7003fb5dfbc}
      \strng{fullhash}{fb687e60b5c9a78610ecb7003fb5dfbc}
      \strng{bibnamehash}{fb687e60b5c9a78610ecb7003fb5dfbc}
      \strng{authorbibnamehash}{fb687e60b5c9a78610ecb7003fb5dfbc}
      \strng{authornamehash}{fb687e60b5c9a78610ecb7003fb5dfbc}
      \strng{authorfullhash}{fb687e60b5c9a78610ecb7003fb5dfbc}
      \field{sortinit}{1}
      \field{sortinithash}{2174f786c6195e7fe2ee1c229b416e29}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Canonical labelling of graphs (CL, for short) can be used, e.g., to test isomorphism. We prove that a simple vertex classification procedure results after only two refinement steps in a CL of random graphs with probability 1 - exp(-cn). With a slight modification we obtain a linear time CL algorithm with only exp(-cn log n/log log n) probability of failure. An additional depth-first search yields a CL of all graphs in linear average time.}
      \field{booktitle}{20th Annual Symposium on Foundations of Computer Science (sfcs 1979)}
      \field{month}{10}
      \field{title}{Canonical labelling of graphs in linear average time}
      \field{year}{1979}
      \verb{doi}
      \verb 10.1109/sfcs.1979.8
      \endverb
      \verb{urlraw}
      \verb https://ieeexplore.ieee.org/abstract/document/4567999
      \endverb
      \verb{url}
      \verb https://ieeexplore.ieee.org/abstract/document/4567999
      \endverb
    \endentry
    \entry{2007_Borgwardt_BOOK}{book}{}
      \name{author}{1}{}{%
        {{hash=87ee24f2394a5abe724cb8c5f7b9a008}{%
           family={Borgwardt},
           familyi={B\bibinitperiod},
           given={Karsten\bibnamedelima Michael},
           giveni={K\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
      }
      \strng{namehash}{87ee24f2394a5abe724cb8c5f7b9a008}
      \strng{fullhash}{87ee24f2394a5abe724cb8c5f7b9a008}
      \strng{bibnamehash}{87ee24f2394a5abe724cb8c5f7b9a008}
      \strng{authorbibnamehash}{87ee24f2394a5abe724cb8c5f7b9a008}
      \strng{authornamehash}{87ee24f2394a5abe724cb8c5f7b9a008}
      \strng{authorfullhash}{87ee24f2394a5abe724cb8c5f7b9a008}
      \field{sortinit}{1}
      \field{sortinithash}{2174f786c6195e7fe2ee1c229b416e29}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{title}{Graph Kernels}
      \field{year}{2007}
      \verb{file}
      \verb :/home/fabrice/Documents/Uni/Literature/Papers/2007_Borgwardt_BOOK.pdf:PDF
      \endverb
      \verb{urlraw}
      \verb https://edoc.ub.uni-muenchen.de/archive/00007169/
      \endverb
      \verb{url}
      \verb https://edoc.ub.uni-muenchen.de/archive/00007169/
      \endverb
    \endentry
    \entry{2002_Scholkopf_CONF}{book}{}
      \true{moreauthor}
      \true{morelabelname}
      \name{author}{3}{}{%
        {{hash=b9c00dbde6a527964ea054f148d9448a}{%
           family={Schökopf},
           familyi={S\bibinitperiod},
           given={Bernhard},
           giveni={B\bibinitperiod}}}%
        {{hash=2df107c3366eadfba1b6ade0345e7fd2}{%
           family={Smola},
           familyi={S\bibinitperiod},
           given={Alexander\bibnamedelima J.},
           giveni={A\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
        {{hash=93da2819ab01d8a5e7bae39ce6f17c1f}{%
           family={Bach},
           familyi={B\bibinitperiod},
           given={Francis},
           giveni={F\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {MIT press}%
      }
      \strng{namehash}{58aaeebb7f6c466847674c7e85df24b3}
      \strng{fullhash}{58aaeebb7f6c466847674c7e85df24b3}
      \strng{bibnamehash}{58aaeebb7f6c466847674c7e85df24b3}
      \strng{authorbibnamehash}{58aaeebb7f6c466847674c7e85df24b3}
      \strng{authornamehash}{58aaeebb7f6c466847674c7e85df24b3}
      \strng{authorfullhash}{58aaeebb7f6c466847674c7e85df24b3}
      \field{sortinit}{1}
      \field{sortinithash}{2174f786c6195e7fe2ee1c229b416e29}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{title}{Learning with kernels: support vector machines, regularization, optimization, and beyond}
      \field{year}{2002}
    \endentry
    \entry{1996_Drucker_CONF}{article}{}
      \name{author}{5}{}{%
        {{hash=e4edd88c0b3e80515990a333458f69a4}{%
           family={Drucker},
           familyi={D\bibinitperiod},
           given={Harris},
           giveni={H\bibinitperiod}}}%
        {{hash=6b5ce974c0337c832bacb16bd8bf3f50}{%
           family={Burges},
           familyi={B\bibinitperiod},
           given={Christopher\bibnamedelima J.},
           giveni={C\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
        {{hash=effc3d6435ce22d99e832f7c76ff823b}{%
           family={Kaufman},
           familyi={K\bibinitperiod},
           given={Linda},
           giveni={L\bibinitperiod}}}%
        {{hash=a4d2eb3aadfce48c1b00303f0988e905}{%
           family={Smola},
           familyi={S\bibinitperiod},
           given={Alex},
           giveni={A\bibinitperiod}}}%
        {{hash=c2b3e05872463585b4be6aab10d10d63}{%
           family={Vapnik},
           familyi={V\bibinitperiod},
           given={Vladimir},
           giveni={V\bibinitperiod}}}%
      }
      \strng{namehash}{0ad41dcd44cdde3d7b130870f66c4956}
      \strng{fullhash}{47f7635642b10fd120e66052f1a0d3b4}
      \strng{bibnamehash}{0ad41dcd44cdde3d7b130870f66c4956}
      \strng{authorbibnamehash}{0ad41dcd44cdde3d7b130870f66c4956}
      \strng{authornamehash}{0ad41dcd44cdde3d7b130870f66c4956}
      \strng{authorfullhash}{47f7635642b10fd120e66052f1a0d3b4}
      \field{sortinit}{1}
      \field{sortinithash}{2174f786c6195e7fe2ee1c229b416e29}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{Advances in neural information processing systems}
      \field{title}{Support vector regression machines}
      \field{volume}{9}
      \field{year}{1996}
    \endentry
    \entry{1996_Vapnik_CONF}{article}{}
      \name{author}{3}{}{%
        {{hash=c2b3e05872463585b4be6aab10d10d63}{%
           family={Vapnik},
           familyi={V\bibinitperiod},
           given={Vladimir},
           giveni={V\bibinitperiod}}}%
        {{hash=4b7527df8a8d3a54d3c06856c916c645}{%
           family={Golowich},
           familyi={G\bibinitperiod},
           given={Steven},
           giveni={S\bibinitperiod}}}%
        {{hash=a4d2eb3aadfce48c1b00303f0988e905}{%
           family={Smola},
           familyi={S\bibinitperiod},
           given={Alex},
           giveni={A\bibinitperiod}}}%
      }
      \strng{namehash}{4c90cbe21cae7e03a072c515c9225336}
      \strng{fullhash}{4c90cbe21cae7e03a072c515c9225336}
      \strng{bibnamehash}{4c90cbe21cae7e03a072c515c9225336}
      \strng{authorbibnamehash}{4c90cbe21cae7e03a072c515c9225336}
      \strng{authornamehash}{4c90cbe21cae7e03a072c515c9225336}
      \strng{authorfullhash}{4c90cbe21cae7e03a072c515c9225336}
      \field{sortinit}{1}
      \field{sortinithash}{2174f786c6195e7fe2ee1c229b416e29}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{Advances in neural information processing systems}
      \field{title}{Support vector method for function approximation, regression estimation and signal processing}
      \field{volume}{9}
      \field{year}{1996}
    \endentry
    \entry{1997_Schoelkopf_CONF}{incollection}{}
      \name{author}{3}{}{%
        {{hash=ca31cc11ec9370460148c3a9c48fce45}{%
           family={Schölkopf},
           familyi={S\bibinitperiod},
           given={Bernhard},
           giveni={B\bibinitperiod}}}%
        {{hash=1817acab40d9caaac71e1597049b7f5e}{%
           family={Smola},
           familyi={S\bibinitperiod},
           given={Alexander},
           giveni={A\bibinitperiod}}}%
        {{hash=9f1b6144a45b1967e989e74552e37ada}{%
           family={Müller},
           familyi={M\bibinitperiod},
           given={Klaus-Robert},
           giveni={K\bibinithyphendelim R\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Springer Berlin Heidelberg}%
      }
      \strng{namehash}{8bbec8bef3418303f4926c0829c71fe1}
      \strng{fullhash}{8bbec8bef3418303f4926c0829c71fe1}
      \strng{bibnamehash}{8bbec8bef3418303f4926c0829c71fe1}
      \strng{authorbibnamehash}{8bbec8bef3418303f4926c0829c71fe1}
      \strng{authornamehash}{8bbec8bef3418303f4926c0829c71fe1}
      \strng{authorfullhash}{8bbec8bef3418303f4926c0829c71fe1}
      \field{sortinit}{1}
      \field{sortinithash}{2174f786c6195e7fe2ee1c229b416e29}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{A new method for performing a nonlinear form of Principal Component Analysis is proposed. By the use of integral operator kernel functions, one can efficiently compute principal components in highdimensional feature spaces, related to input space by some nonlinear map; for instance the space of all possible d-pixel products in images. We give the derivation of the method and present experimental results on polynomial feature extraction for pattern recognition.}
      \field{booktitle}{Lecture Notes in Computer Science}
      \field{title}{Kernel principal component analysis}
      \field{year}{1997}
      \field{pages}{583\bibrangedash 588}
      \range{pages}{6}
      \verb{doi}
      \verb 10.1007/bfb0020217
      \endverb
    \endentry
    \entry{2018_Vert_CONF}{inproceedings}{}
      \name{author}{1}{}{%
        {{hash=0df2e0c86d89bfaf4f3726c0bc382d4f}{%
           family={Vert},
           familyi={V\bibinitperiod},
           given={Jean-Philippe},
           giveni={J\bibinithyphendelim P\bibinitperiod}}}%
      }
      \strng{namehash}{0df2e0c86d89bfaf4f3726c0bc382d4f}
      \strng{fullhash}{0df2e0c86d89bfaf4f3726c0bc382d4f}
      \strng{bibnamehash}{0df2e0c86d89bfaf4f3726c0bc382d4f}
      \strng{authorbibnamehash}{0df2e0c86d89bfaf4f3726c0bc382d4f}
      \strng{authornamehash}{0df2e0c86d89bfaf4f3726c0bc382d4f}
      \strng{authorfullhash}{0df2e0c86d89bfaf4f3726c0bc382d4f}
      \field{sortinit}{1}
      \field{sortinithash}{2174f786c6195e7fe2ee1c229b416e29}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We prove that the optimal assignment kernel, proposed recently as an attempt to embed labeled graphs and more generally tuples of basic data to a Hilbert space, is in fact not always positive definite.}
      \field{day}{27}
      \field{month}{10}
      \field{title}{The optimal assignment kernel is not positive definite}
      \field{year}{2018}
      \field{dateera}{ce}
      \verb{eprint}
      \verb arXiv:0801.4061v1[cs.LG]
      \endverb
      \verb{file}
      \verb :/home/fabrice/Documents/Uni/Literature/Papers/2018_Vert_CONF.pdf:PDF
      \endverb
      \verb{urlraw}
      \verb https://arxiv.org/abs/0801.4061
      \endverb
      \verb{url}
      \verb https://arxiv.org/abs/0801.4061
      \endverb
    \endentry
    \entry{1984_Berg_BOOK}{book}{}
      \name{author}{3}{}{%
        {{hash=15b2037e80532296ca33d5f3c87ba2c1}{%
           family={Berg},
           familyi={B\bibinitperiod},
           given={Christian},
           giveni={C\bibinitperiod}}}%
        {{hash=21253d553e7301e4eaee151e9d134c3d}{%
           family={Christensen},
           familyi={C\bibinitperiod},
           given={Jens\bibnamedelimb Peter\bibnamedelima Reus},
           giveni={J\bibinitperiod\bibinitdelim P\bibinitperiod\bibinitdelim R\bibinitperiod}}}%
        {{hash=3bad9509b4c1638b84419b9d870641fa}{%
           family={Ressel},
           familyi={R\bibinitperiod},
           given={Paul},
           giveni={P\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Springer New York}%
      }
      \strng{namehash}{aea9d35ea555174e06614a453bad88c5}
      \strng{fullhash}{aea9d35ea555174e06614a453bad88c5}
      \strng{bibnamehash}{aea9d35ea555174e06614a453bad88c5}
      \strng{authorbibnamehash}{aea9d35ea555174e06614a453bad88c5}
      \strng{authornamehash}{aea9d35ea555174e06614a453bad88c5}
      \strng{authorfullhash}{aea9d35ea555174e06614a453bad88c5}
      \field{sortinit}{1}
      \field{sortinithash}{2174f786c6195e7fe2ee1c229b416e29}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{title}{Harmonic Analysis on Semigroups}
      \field{year}{1984}
      \verb{doi}
      \verb 10.1007/978-1-4612-1128-0
      \endverb
    \endentry
    \entry{2015_Feragen_IEEE}{inproceedings}{}
      \name{author}{4}{}{%
        {{hash=e0b97a8d968a77967f24520cd9f76af9}{%
           family={Feragen},
           familyi={F\bibinitperiod},
           given={Aasa},
           giveni={A\bibinitperiod}}}%
        {{hash=11ae41b44f0783ffa87120dbbd2c3833}{%
           family={Søren},
           familyi={S\bibinitperiod},
           given={Hauberg},
           giveni={H\bibinitperiod}}}%
        {{hash=f608465d8049e67909d0eaf8a95f98ab}{%
           family={Dtu},
           familyi={D\bibinitperiod},
           given={Compute},
           giveni={C\bibinitperiod}}}%
        {{hash=424214945ba5615eca039bfe5d731c09}{%
           family={Denmark},
           familyi={D\bibinitperiod}}}%
      }
      \strng{namehash}{34c93c3de5402d4812a7ac6d13884e3a}
      \strng{fullhash}{cf8185d1e9b233142b6152095b100014}
      \strng{bibnamehash}{34c93c3de5402d4812a7ac6d13884e3a}
      \strng{authorbibnamehash}{34c93c3de5402d4812a7ac6d13884e3a}
      \strng{authornamehash}{34c93c3de5402d4812a7ac6d13884e3a}
      \strng{authorfullhash}{cf8185d1e9b233142b6152095b100014}
      \field{sortinit}{1}
      \field{sortinithash}{2174f786c6195e7fe2ee1c229b416e29}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We consider kernel methods on general geodesic metric spaces and provide both negative and positive results. First we show that the common Gaussian kernel can only be generalized to a positive definite kernel on a geodesic metric space if the space is flat. As a result, for data on a Riemannian manifold, the geodesic Gaussian kernel is only positive definite if the Riemannian manifold is Euclidean. This implies that any attempt to design geodesic Gaussian kernels on curved Riemannian manifolds is futile. However, we show that for spaces with conditionally negative definite distances the geodesic Laplacian kernel can be generalized while retaining positive definiteness. This implies that geodesic Laplacian kernels can be generalized to some curved spaces, including spheres and hyperbolic spaces. Our theoretical results are verified empirically.}
      \field{title}{Geodesic Exponential Kernels: When Curvature and Linearity Conflict}
      \field{year}{2015}
      \verb{file}
      \verb :/home/fabrice/Documents/Uni/Literature/Papers/2015_Feragen_IEEE.pdf:PDF
      \endverb
      \verb{urlraw}
      \verb https://www.cv-foundation.org/openaccess/content_cvpr_2015/html/Feragen_Geodesic_Exponential_Kernels_2015_CVPR_paper.html
      \endverb
      \verb{url}
      \verb https://www.cv-foundation.org/openaccess/content_cvpr_2015/html/Feragen_Geodesic_Exponential_Kernels_2015_CVPR_paper.html
      \endverb
    \endentry
    \entry{2015_Rupp_CONF}{article}{}
      \name{author}{1}{}{%
        {{hash=0eba1e8d9af2b92d47a642a803034003}{%
           family={Rupp},
           familyi={R\bibinitperiod},
           given={Matthias},
           giveni={M\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Wiley}%
      }
      \strng{namehash}{0eba1e8d9af2b92d47a642a803034003}
      \strng{fullhash}{0eba1e8d9af2b92d47a642a803034003}
      \strng{bibnamehash}{0eba1e8d9af2b92d47a642a803034003}
      \strng{authorbibnamehash}{0eba1e8d9af2b92d47a642a803034003}
      \strng{authornamehash}{0eba1e8d9af2b92d47a642a803034003}
      \strng{authorfullhash}{0eba1e8d9af2b92d47a642a803034003}
      \field{sortinit}{1}
      \field{sortinithash}{2174f786c6195e7fe2ee1c229b416e29}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Models that combine quantum mechanics (QM) with machine learning (ML) promise to deliver the accuracy of QM at the speed of ML. This hands-on tutorial introduces the reader to QM/ML models based on kernel learning, an elegant, systematically nonlinear form of ML. Pseudocode and a reference implementation are provided, enabling the reader to reproduce results from recent publications where atomization energies of small organic molecules are predicted using kernel ridge regression. © 2015 Wiley Periodicals, Inc.}
      \field{journaltitle}{International Journal of Quantum Chemistry}
      \field{month}{7}
      \field{number}{16}
      \field{title}{Machine learning for quantum mechanics in a nutshell}
      \field{volume}{115}
      \field{year}{2015}
      \field{pages}{1058\bibrangedash 1073}
      \range{pages}{16}
      \verb{doi}
      \verb 10.1002/qua.24954
      \endverb
    \endentry
    \entry{1938_Schoenberg_CONF}{article}{}
      \name{author}{1}{}{%
        {{hash=efec27ce16c66f002cf9dadaa137b3da}{%
           family={Schoenberg},
           familyi={S\bibinitperiod},
           given={I.\bibnamedelimi J.},
           giveni={I\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {JSTOR}%
      }
      \strng{namehash}{efec27ce16c66f002cf9dadaa137b3da}
      \strng{fullhash}{efec27ce16c66f002cf9dadaa137b3da}
      \strng{bibnamehash}{efec27ce16c66f002cf9dadaa137b3da}
      \strng{authorbibnamehash}{efec27ce16c66f002cf9dadaa137b3da}
      \strng{authornamehash}{efec27ce16c66f002cf9dadaa137b3da}
      \strng{authorfullhash}{efec27ce16c66f002cf9dadaa137b3da}
      \field{sortinit}{1}
      \field{sortinithash}{2174f786c6195e7fe2ee1c229b416e29}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{The Annals of Mathematics}
      \field{month}{10}
      \field{number}{4}
      \field{title}{Metric Spaces and Completely Monotone Functions}
      \field{volume}{39}
      \field{year}{1938}
      \field{pages}{811}
      \range{pages}{1}
      \verb{doi}
      \verb 10.2307/1968466
      \endverb
    \endentry
    \entry{2017_Bollobas_BOOK}{book}{}
      \name{author}{7}{}{%
        {{hash=69f9382e4d6c45c5bdfeffe9417b250b}{%
           family={Bollob{á}s},
           familyi={B\bibinitperiod},
           given={B{é}la},
           giveni={B\bibinitperiod}}}%
        {{hash=205bfcbd8ec5b58401ee1d5cbd94a5de}{%
           family={Fulton},
           familyi={F\bibinitperiod},
           given={William},
           giveni={W\bibinitperiod}}}%
        {{hash=ec55cf81516f35a3468ce038bee79b76}{%
           family={Katok},
           familyi={K\bibinitperiod},
           given={Anatole},
           giveni={A\bibinitperiod}}}%
        {{hash=f4bbd7ccd0250c57c48088142084a597}{%
           family={Kirwan},
           familyi={K\bibinitperiod},
           given={Frances},
           giveni={F\bibinitperiod}}}%
        {{hash=02646eacc4c6de451af9108071677884}{%
           family={Sarnak},
           familyi={S\bibinitperiod},
           given={Peter},
           giveni={P\bibinitperiod}}}%
        {{hash=7269c7c834dddf30f6b8e7cb7b0d4790}{%
           family={Simon},
           familyi={S\bibinitperiod},
           given={Barry},
           giveni={B\bibinitperiod}}}%
        {{hash=c4c4cff4b5dd332e89ddb3360bf723b9}{%
           family={Totaro},
           familyi={T\bibinitperiod},
           given={Burt},
           giveni={B\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Cambridge University Press}%
      }
      \strng{namehash}{2cabae65fb48575168482289a0a5739a}
      \strng{fullhash}{88ef9115e4972d1e916d29dde3d23361}
      \strng{bibnamehash}{2cabae65fb48575168482289a0a5739a}
      \strng{authorbibnamehash}{2cabae65fb48575168482289a0a5739a}
      \strng{authornamehash}{2cabae65fb48575168482289a0a5739a}
      \strng{authorfullhash}{88ef9115e4972d1e916d29dde3d23361}
      \field{sortinit}{1}
      \field{sortinithash}{2174f786c6195e7fe2ee1c229b416e29}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{title}{New Mathematical Monographs}
      \field{year}{2017}
    \endentry
    \entry{2018_Gardner_IEEE}{article}{}
      \name{author}{4}{}{%
        {{hash=ff23f6d1c0c1d14a51fe1dfd76a314ae}{%
           family={Gardner},
           familyi={G\bibinitperiod},
           given={Andrew},
           giveni={A\bibinitperiod}}}%
        {{hash=50e9fd240b2dbccaae6e831f619ffe2a}{%
           family={Duncan},
           familyi={D\bibinitperiod},
           given={Christian\bibnamedelima A.},
           giveni={C\bibinitperiod\bibinitdelim A\bibinitperiod}}}%
        {{hash=f02478fd94bac8ad5fa7a6387127c4fa}{%
           family={Kanno},
           familyi={K\bibinitperiod},
           given={Jinko},
           giveni={J\bibinitperiod}}}%
        {{hash=1fb8ab6a34919f12983e3f932c992619}{%
           family={Selmic},
           familyi={S\bibinitperiod},
           given={Rastko\bibnamedelima R.},
           giveni={R\bibinitperiod\bibinitdelim R\bibinitperiod}}}%
      }
      \list{publisher}{2}{%
        {Institute of Electrical}%
        {Electronics Engineers ({IEEE})}%
      }
      \strng{namehash}{f92fede702ed470c012b09f5e4b3c1b1}
      \strng{fullhash}{ad7289d7bac44a707ea655eeb60c9c0b}
      \strng{bibnamehash}{f92fede702ed470c012b09f5e4b3c1b1}
      \strng{authorbibnamehash}{f92fede702ed470c012b09f5e4b3c1b1}
      \strng{authornamehash}{f92fede702ed470c012b09f5e4b3c1b1}
      \strng{authorfullhash}{ad7289d7bac44a707ea655eeb60c9c0b}
      \field{sortinit}{1}
      \field{sortinithash}{2174f786c6195e7fe2ee1c229b416e29}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{{IEEE} Transactions on Cybernetics}
      \field{month}{11}
      \field{number}{11}
      \field{title}{On the Definiteness of Earth Mover's Distance and Its Relation to Set Intersection}
      \field{volume}{48}
      \field{year}{2018}
      \field{pages}{3184\bibrangedash 3196}
      \range{pages}{13}
      \verb{doi}
      \verb 10.1109/tcyb.2017.2761798
      \endverb
    \endentry
    \entry{1987_Rousseeuw_ELSEVIER}{article}{}
      \name{author}{1}{}{%
        {{hash=a4498124646e276cccc6c0210a229afc}{%
           family={Rousseeuw},
           familyi={R\bibinitperiod},
           given={Peter\bibnamedelima J.},
           giveni={P\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Elsevier {BV}}%
      }
      \strng{namehash}{a4498124646e276cccc6c0210a229afc}
      \strng{fullhash}{a4498124646e276cccc6c0210a229afc}
      \strng{bibnamehash}{a4498124646e276cccc6c0210a229afc}
      \strng{authorbibnamehash}{a4498124646e276cccc6c0210a229afc}
      \strng{authornamehash}{a4498124646e276cccc6c0210a229afc}
      \strng{authorfullhash}{a4498124646e276cccc6c0210a229afc}
      \field{sortinit}{1}
      \field{sortinithash}{2174f786c6195e7fe2ee1c229b416e29}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{A new graphical display is proposed for partitioning techniques. Each cluster is represented by a so-called silhouette, which is based on the comparison of its tightness and separation. This silhouette shows which objects lie well within their cluster, and which ones are merely somewhere in between clusters. The entire clustering is displayed by combining the silhouettes into a single plot, allowing an appreciation of the relative quality of the clusters and an overview of the data configuration. The average silhouette width provides an evaluation of clustering validity, and might be used to select an ‘appropriate’ number of clusters.}
      \field{journaltitle}{Journal of Computational and Applied Mathematics}
      \field{month}{11}
      \field{title}{Silhouettes: A graphical aid to the interpretation and validation of cluster analysis}
      \field{volume}{20}
      \field{year}{1987}
      \field{pages}{53\bibrangedash 65}
      \range{pages}{13}
      \verb{doi}
      \verb 10.1016/0377-0427(87)90125-7
      \endverb
      \verb{urlraw}
      \verb https://www.sciencedirect.com/science/article/pii/0377042787901257
      \endverb
      \verb{url}
      \verb https://www.sciencedirect.com/science/article/pii/0377042787901257
      \endverb
    \endentry
    \entry{1979_Davies_IEEE}{article}{}
      \name{author}{2}{}{%
        {{hash=f4432b7833b1b121522e63442ce5ddb2}{%
           family={Davies},
           familyi={D\bibinitperiod},
           given={David\bibnamedelima L.},
           giveni={D\bibinitperiod\bibinitdelim L\bibinitperiod}}}%
        {{hash=68d65706974935ad0c38aa86bab4b082}{%
           family={Bouldin},
           familyi={B\bibinitperiod},
           given={Donald\bibnamedelima W.},
           giveni={D\bibinitperiod\bibinitdelim W\bibinitperiod}}}%
      }
      \list{publisher}{2}{%
        {Institute of Electrical}%
        {Electronics Engineers ({IEEE})}%
      }
      \strng{namehash}{5849fdd60b0a59bc8c11b9b6fbf2da98}
      \strng{fullhash}{5849fdd60b0a59bc8c11b9b6fbf2da98}
      \strng{bibnamehash}{5849fdd60b0a59bc8c11b9b6fbf2da98}
      \strng{authorbibnamehash}{5849fdd60b0a59bc8c11b9b6fbf2da98}
      \strng{authornamehash}{5849fdd60b0a59bc8c11b9b6fbf2da98}
      \strng{authorfullhash}{5849fdd60b0a59bc8c11b9b6fbf2da98}
      \field{sortinit}{1}
      \field{sortinithash}{2174f786c6195e7fe2ee1c229b416e29}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{A measure is presented which indicates the similarity of clusters which are assumed to have a data density which is a decreasing function of distance from a vector characteristic of the cluster. The measure can be used to infer the appropriateness of data partitions and can therefore be used to compare relative appropriateness of various divisions of the data. The measure does not depend on either the number of clusters analyzed nor the method of partitioning of the data and can be used to guide a cluster seeking algorithm.}
      \field{journaltitle}{{IEEE} Transactions on Pattern Analysis and Machine Intelligence}
      \field{month}{4}
      \field{number}{2}
      \field{title}{A Cluster Separation Measure}
      \field{volume}{{PAMI}-1}
      \field{year}{1979}
      \field{pages}{224\bibrangedash 227}
      \range{pages}{4}
      \verb{doi}
      \verb 10.1109/tpami.1979.4766909
      \endverb
      \verb{urlraw}
      \verb https://ieeexplore.ieee.org/document/4766909
      \endverb
      \verb{url}
      \verb https://ieeexplore.ieee.org/document/4766909
      \endverb
      \keyw{Davies-Bouldin Index}
    \endentry
    \entry{1974_Calinski_CONF}{article}{}
      \name{author}{2}{}{%
        {{hash=84bae0ee62b5d0a81ed1edf6f5fde677}{%
           family={Calinski},
           familyi={C\bibinitperiod},
           given={T.},
           giveni={T\bibinitperiod}}}%
        {{hash=49fd8aa4745a616e2f24afa4008ac818}{%
           family={Harabasz},
           familyi={H\bibinitperiod},
           given={J.},
           giveni={J\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Informa {UK} Limited}%
      }
      \strng{namehash}{6d133a4206f26900f74ccb4bdf258391}
      \strng{fullhash}{6d133a4206f26900f74ccb4bdf258391}
      \strng{bibnamehash}{6d133a4206f26900f74ccb4bdf258391}
      \strng{authorbibnamehash}{6d133a4206f26900f74ccb4bdf258391}
      \strng{authornamehash}{6d133a4206f26900f74ccb4bdf258391}
      \strng{authorfullhash}{6d133a4206f26900f74ccb4bdf258391}
      \field{sortinit}{1}
      \field{sortinithash}{2174f786c6195e7fe2ee1c229b416e29}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{A method for identifying clusters of points in a multidimensional Euclidean space is described and its application to taxonomy considered. It reconciles, in a sense, two different approaches to the investigation of the spatial relationships between the points, viz., the agglomerative and the divisive methods. A graph, the shortest dendrite of Florek etal. (1951a), is constructed on a nearest neighbour basis and then divided into clusters by applying the criterion of minimum within cluster sum of squares. This procedure ensures an effective reduction of the number of possible splits. The method may be applied to a dichotomous division, but is perfectly suitable also for a global division into any number of clusters. An informal indicator of the "best number" of clusters is suggested. It is a"variance ratio criterion" giving some insight into the structure of the points. The method is illustrated by three examples, one of which is original. The results obtained by the dendrite method are compared with those obtained by using the agglomerative method or Ward (1963) and the divisive method of Edwards and Cavalli-Sforza (1965).}
      \field{journaltitle}{Communications in Statistics - Theory and Methods}
      \field{number}{1}
      \field{title}{A dendrite method for cluster analysis}
      \field{volume}{3}
      \field{year}{1974}
      \field{pages}{1\bibrangedash 27}
      \range{pages}{27}
      \verb{doi}
      \verb 10.1080/03610927408827101
      \endverb
    \endentry
    \entry{1992_Boser_CONF}{inproceedings}{}
      \name{author}{3}{}{%
        {{hash=a012d21d84fb6ec87416be7815d7fbd9}{%
           family={Boser},
           familyi={B\bibinitperiod},
           given={Bernhard\bibnamedelima E.},
           giveni={B\bibinitperiod\bibinitdelim E\bibinitperiod}}}%
        {{hash=495d7b70e4ce0aae74ceb20f9a611ed1}{%
           family={Guyon},
           familyi={G\bibinitperiod},
           given={Isabelle\bibnamedelima M.},
           giveni={I\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
        {{hash=196dca851d60592649a7d411a61357a1}{%
           family={Vapnik},
           familyi={V\bibinitperiod},
           given={Vladimir\bibnamedelima N.},
           giveni={V\bibinitperiod\bibinitdelim N\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {{ACM} Press}%
      }
      \strng{namehash}{f442a8df2270d920afa6e9741ef1627e}
      \strng{fullhash}{f442a8df2270d920afa6e9741ef1627e}
      \strng{bibnamehash}{f442a8df2270d920afa6e9741ef1627e}
      \strng{authorbibnamehash}{f442a8df2270d920afa6e9741ef1627e}
      \strng{authornamehash}{f442a8df2270d920afa6e9741ef1627e}
      \strng{authorfullhash}{f442a8df2270d920afa6e9741ef1627e}
      \field{sortinit}{1}
      \field{sortinithash}{2174f786c6195e7fe2ee1c229b416e29}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{Proceedings of the fifth annual workshop on Computational learning theory - {COLT} {'}92}
      \field{title}{A training algorithm for optimal margin classifiers}
      \field{year}{1992}
      \verb{doi}
      \verb 10.1145/130385.130401
      \endverb
    \endentry
    \entry{2003_Hsu_CONF}{inproceedings}{}
      \name{author}{3}{}{%
        {{hash=50d1a66d4807a3d7807226403051f1e7}{%
           family={Hsu},
           familyi={H\bibinitperiod},
           given={Chih-Wei},
           giveni={C\bibinithyphendelim W\bibinitperiod}}}%
        {{hash=90dbdcacecdffc9ea33bf0a0d370c416}{%
           family={Chang},
           familyi={C\bibinitperiod},
           given={Chih-Chung},
           giveni={C\bibinithyphendelim C\bibinitperiod}}}%
        {{hash=bb8c32ec740b902c4f066796b083badc}{%
           family={Lin},
           familyi={L\bibinitperiod},
           given={Chih-Jen},
           giveni={C\bibinithyphendelim J\bibinitperiod}}}%
      }
      \strng{namehash}{716bb0d9bc1c445870907004cfe19c1f}
      \strng{fullhash}{716bb0d9bc1c445870907004cfe19c1f}
      \strng{bibnamehash}{716bb0d9bc1c445870907004cfe19c1f}
      \strng{authorbibnamehash}{716bb0d9bc1c445870907004cfe19c1f}
      \strng{authornamehash}{716bb0d9bc1c445870907004cfe19c1f}
      \strng{authorfullhash}{716bb0d9bc1c445870907004cfe19c1f}
      \field{sortinit}{1}
      \field{sortinithash}{2174f786c6195e7fe2ee1c229b416e29}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{The support vector machine (SVM) is a popular classification technique. However, beginners who are not familiar with SVM often get unsatisfactory results since they miss some easy but significant steps. In this guide, we propose a simple procedure which usually gives reasonable results.}
      \field{title}{A Practical Guide to Support Vector Classification}
      \field{year}{2003}
      \verb{file}
      \verb :/home/fabrice/Documents/Uni/Literature/Papers/2003_Hsu_CONF.pdf:PDF
      \endverb
      \verb{urlraw}
      \verb http://www.datascienceassn.org/sites/default/files/Practical Guide to Support Vector Classification.pdf
      \endverb
      \verb{url}
      \verb http://www.datascienceassn.org/sites/default/files/Practical%20Guide%20to%20Support%20Vector%20Classification.pdf
      \endverb
    \endentry
    \entry{2008_Maaten_CONF}{article}{}
      \name{author}{2}{}{%
        {{hash=0ef07e10598a5186b30357de23ebbaff}{%
           family={Van\bibnamedelimb der\bibnamedelima Maaten},
           familyi={V\bibinitperiod\bibinitdelim d\bibinitperiod\bibinitdelim M\bibinitperiod},
           given={Laurens},
           giveni={L\bibinitperiod}}}%
        {{hash=9a8750ccdb2a4cf14d2655face1ce016}{%
           family={Hinton},
           familyi={H\bibinitperiod},
           given={Geoffrey},
           giveni={G\bibinitperiod}}}%
      }
      \strng{namehash}{15de65b55871c0624a03b5e07f188e52}
      \strng{fullhash}{15de65b55871c0624a03b5e07f188e52}
      \strng{bibnamehash}{15de65b55871c0624a03b5e07f188e52}
      \strng{authorbibnamehash}{15de65b55871c0624a03b5e07f188e52}
      \strng{authornamehash}{15de65b55871c0624a03b5e07f188e52}
      \strng{authorfullhash}{15de65b55871c0624a03b5e07f188e52}
      \field{sortinit}{1}
      \field{sortinithash}{2174f786c6195e7fe2ee1c229b416e29}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{Journal of machine learning research}
      \field{number}{11}
      \field{title}{Visualizing data using t-{SNE}.}
      \field{volume}{9}
      \field{year}{2008}
    \endentry
    \entry{2019_Ivanov_CONF}{article}{}
      \name{author}{3}{}{%
        {{hash=2ea4f156a87262385479576db0d51a33}{%
           family={Ivanov},
           familyi={I\bibinitperiod},
           given={Sergei},
           giveni={S\bibinitperiod}}}%
        {{hash=8ecde70a9d682a9efefaa9e340a67a67}{%
           family={Sviridov},
           familyi={S\bibinitperiod},
           given={Sergei},
           giveni={S\bibinitperiod}}}%
        {{hash=2b0f7cb6d0f87166c23fc14ee306f97a}{%
           family={Burnaev},
           familyi={B\bibinitperiod},
           given={Evgeny},
           giveni={E\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{4518e0f00807ec0c0d7a03f275307557}
      \strng{fullhash}{4518e0f00807ec0c0d7a03f275307557}
      \strng{bibnamehash}{4518e0f00807ec0c0d7a03f275307557}
      \strng{authorbibnamehash}{4518e0f00807ec0c0d7a03f275307557}
      \strng{authornamehash}{4518e0f00807ec0c0d7a03f275307557}
      \strng{authorfullhash}{4518e0f00807ec0c0d7a03f275307557}
      \field{sortinit}{1}
      \field{sortinithash}{2174f786c6195e7fe2ee1c229b416e29}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In recent years there has been a rapid increase in classification methods on graph structured data. Both in graph kernels and graph neural networks, one of the implicit assumptions of successful state-of-the-art models was that incorporating graph isomorphism features into the architecture leads to better empirical performance. However, as we discover in this work, commonly used data sets for graph classification have repeating instances which cause the problem of isomorphism bias, i.e. artificially increasing the accuracy of the models by memorizing target information from the training set. This prevents fair competition of the algorithms and raises a question of the validity of the obtained results. We analyze 54 data sets, previously extensively used for graph-related tasks, on the existence of isomorphism bias, give a set of recommendations to machine learning practitioners to properly set up their models, and open source new data sets for the future experiments.}
      \field{title}{Understanding Isomorphism Bias in Graph Data Sets}
      \field{year}{2019}
      \verb{doi}
      \verb 10.48550/ARXIV.1910.12091
      \endverb
      \verb{urlraw}
      \verb https://arxiv.org/abs/1910.12091
      \endverb
      \verb{url}
      \verb https://arxiv.org/abs/1910.12091
      \endverb
      \keyw{Machine Learning (cs.LG),Social and Information Networks (cs.SI),Machine Learning (stat.ML),FOS: Computer and information sciences}
    \endentry
    \entry{2020_Hu_CONF}{inproceedings}{}
      \name{author}{8}{}{%
        {{hash=164c7f22cde069c57bf9b80f76441fa9}{%
           family={Hu},
           familyi={H\bibinitperiod},
           given={Weihua},
           giveni={W\bibinitperiod}}}%
        {{hash=2667edba6b12b863d4fc7ec3afba0ede}{%
           family={Fey},
           familyi={F\bibinitperiod},
           given={Matthias},
           giveni={M\bibinitperiod}}}%
        {{hash=5f1df07c5fbd5a91d0e32b8697082857}{%
           family={Zitnik},
           familyi={Z\bibinitperiod},
           given={Marinka},
           giveni={M\bibinitperiod}}}%
        {{hash=5fd8ccf894ae8131d46d95e71572ffae}{%
           family={Dong},
           familyi={D\bibinitperiod},
           given={Yuxiao},
           giveni={Y\bibinitperiod}}}%
        {{hash=f136c99c06f10d114554179d4722b864}{%
           family={Ren},
           familyi={R\bibinitperiod},
           given={Hongyu},
           giveni={H\bibinitperiod}}}%
        {{hash=405a3ad8dc4c66f7ccc340047cb033d3}{%
           family={Liu},
           familyi={L\bibinitperiod},
           given={Bowen},
           giveni={B\bibinitperiod}}}%
        {{hash=4d8195891e857816c8f42626f464a3a8}{%
           family={Catasta},
           familyi={C\bibinitperiod},
           given={Michele},
           giveni={M\bibinitperiod}}}%
        {{hash=900d107125ff0ca84698cb909e4f6c51}{%
           family={Leskovec},
           familyi={L\bibinitperiod},
           given={Jure},
           giveni={J\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{15de1a78b688f5e1daf2849c9671310b}
      \strng{fullhash}{ce1855a2f200320d635b4b554082995f}
      \strng{bibnamehash}{15de1a78b688f5e1daf2849c9671310b}
      \strng{authorbibnamehash}{15de1a78b688f5e1daf2849c9671310b}
      \strng{authornamehash}{15de1a78b688f5e1daf2849c9671310b}
      \strng{authorfullhash}{ce1855a2f200320d635b4b554082995f}
      \field{sortinit}{1}
      \field{sortinithash}{2174f786c6195e7fe2ee1c229b416e29}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We present the Open Graph Benchmark (OGB), a diverse set of challenging and realistic benchmark datasets to facilitate scalable, robust, and reproducible graph machine learning (ML) research. OGB datasets are large-scale, encompass multiple important graph ML tasks, and cover a diverse range of domains, ranging from social and information networks to biological networks, molecular graphs, source code ASTs, and knowledge graphs. For each dataset, we provide a unified evaluation protocol using meaningful application-specific data splits and evaluation metrics. In addition to building the datasets, we also perform extensive benchmark experiments for each dataset. Our experiments suggest that OGB datasets present significant challenges of scalability to large-scale graphs and out-of-distribution generalization under realistic data splits, indicating fruitful opportunities for future research. Finally, OGB provides an automated end-to-end graph ML pipeline that simplifies and standardizes the process of graph data loading, experimental setup, and model evaluation. OGB will be regularly updated and welcomes inputs from the community. OGB datasets as well as data loaders, evaluation scripts, baseline code, and leaderboards are publicly available at https://ogb.stanford.edu/.}
      \field{title}{Open Graph Benchmark: Datasets for Machine Learning on Graphs}
      \field{year}{2020}
      \verb{doi}
      \verb 10.48550/ARXIV.2005.00687
      \endverb
      \verb{file}
      \verb :2020_Hu_CONF.pdf:PDF
      \endverb
      \verb{urlraw}
      \verb https://arxiv.org/abs/2005.00687
      \endverb
      \verb{url}
      \verb https://arxiv.org/abs/2005.00687
      \endverb
      \keyw{Machine Learning (cs.LG),Social and Information Networks (cs.SI),Machine Learning (stat.ML),FOS: Computer and information sciences}
    \endentry
    \entry{2008_Riesen_CONF}{incollection}{}
      \name{author}{2}{}{%
        {{hash=2baff21a8dd8f41605ec19a4057557fb}{%
           family={Riesen},
           familyi={R\bibinitperiod},
           given={Kaspar},
           giveni={K\bibinitperiod}}}%
        {{hash=625c3a38db540fc74378c3ebda8cda48}{%
           family={Bunke},
           familyi={B\bibinitperiod},
           given={Horst},
           giveni={H\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Springer Berlin Heidelberg}%
      }
      \strng{namehash}{7c72451cb96deeb7e9f765ab868b0bd9}
      \strng{fullhash}{7c72451cb96deeb7e9f765ab868b0bd9}
      \strng{bibnamehash}{7c72451cb96deeb7e9f765ab868b0bd9}
      \strng{authorbibnamehash}{7c72451cb96deeb7e9f765ab868b0bd9}
      \strng{authornamehash}{7c72451cb96deeb7e9f765ab868b0bd9}
      \strng{authorfullhash}{7c72451cb96deeb7e9f765ab868b0bd9}
      \field{sortinit}{1}
      \field{sortinithash}{2174f786c6195e7fe2ee1c229b416e29}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In recent years the use of graph based representation has gained popularity in pattern recognition and machine learning. As a matter of fact, object representation by means of graphs has a number of advantages over feature vectors. Therefore, various algorithms for graph based machine learning have been proposed in the literature. However, in contrast with the emerging interest in graph based representation, a lack of standardized graph data sets for benchmarking can be observed. Common practice is that researchers use their own data sets, and this behavior cumbers the objective evaluation of the proposed methods. In order to make the different approaches in graph based machine learning better comparable, the present paper aims at introducing a repository of graph data sets and corresponding benchmarks, covering a wide spectrum of different applications.}
      \field{booktitle}{Lecture Notes in Computer Science}
      \field{title}{{IAM} Graph Database Repository for Graph Based Pattern Recognition and Machine Learning}
      \field{year}{2008}
      \field{pages}{287\bibrangedash 297}
      \range{pages}{11}
      \verb{doi}
      \verb 10.1007/978-3-540-89689-0_33
      \endverb
    \endentry
    \entry{URL_TUDataset_NCI}{online}{}
      \name{author}{1}{}{%
        {{hash=3c08c6a31d5f5666947f4322438780a0}{%
           family={Institute},
           familyi={I\bibinitperiod},
           given={National\bibnamedelima Cancer},
           giveni={N\bibinitperiod\bibinitdelim C\bibinitperiod}}}%
      }
      \strng{namehash}{3c08c6a31d5f5666947f4322438780a0}
      \strng{fullhash}{3c08c6a31d5f5666947f4322438780a0}
      \strng{bibnamehash}{3c08c6a31d5f5666947f4322438780a0}
      \strng{authorbibnamehash}{3c08c6a31d5f5666947f4322438780a0}
      \strng{authornamehash}{3c08c6a31d5f5666947f4322438780a0}
      \strng{authorfullhash}{3c08c6a31d5f5666947f4322438780a0}
      \field{sortinit}{1}
      \field{sortinithash}{2174f786c6195e7fe2ee1c229b416e29}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{title}{AIDS Antiviral Screen Data}
      \field{urlday}{22}
      \field{urlmonth}{11}
      \field{urlyear}{2022}
      \field{year}{2022}
      \field{urldateera}{ce}
      \verb{urlraw}
      \verb https://jonas-moennig.de/how-to-cite-a-website-with-bibtex/
      \endverb
      \verb{url}
      \verb https://jonas-moennig.de/how-to-cite-a-website-with-bibtex/
      \endverb
    \endentry
    \entry{2012_Kriege_CONF}{inproceedings}{}
      \name{author}{2}{}{%
        {{hash=1ddd10a88cb3f30fdb980787b0314429}{%
           family={Kriege},
           familyi={K\bibinitperiod},
           given={Nils},
           giveni={N\bibinitperiod}}}%
        {{hash=a2fd7e6fca32deb028c924ba80cfa4df}{%
           family={Mutzel},
           familyi={M\bibinitperiod},
           given={Petra},
           giveni={P\bibinitperiod}}}%
      }
      \strng{namehash}{a2f79a5960b56fd621e2ee7c3e775439}
      \strng{fullhash}{a2f79a5960b56fd621e2ee7c3e775439}
      \strng{bibnamehash}{a2f79a5960b56fd621e2ee7c3e775439}
      \strng{authorbibnamehash}{a2f79a5960b56fd621e2ee7c3e775439}
      \strng{authornamehash}{a2f79a5960b56fd621e2ee7c3e775439}
      \strng{authorfullhash}{a2f79a5960b56fd621e2ee7c3e775439}
      \field{sortinit}{1}
      \field{sortinithash}{2174f786c6195e7fe2ee1c229b416e29}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We propose graph kernels based on subgraph matchings, i.e. structure-preserving bijections between subgraphs. While recently proposed kernels based on common subgraphs (Wale et al., 2008; Shervashidze et al., 2009) in general can not be applied to attributed graphs, our approach allows to rate mappings of subgraphs by a flexible scoring scheme comparing vertex and edge attributes by kernels. We show that subgraph matching kernels generalize several known kernels. To compute the kernel we propose a graph-theoretical algorithm inspired by a classical relation between common subgraphs of two graphs and cliques in their product graph observed by Levi (1973). Encouraging experimental results on a classification task of real-world graphs are presented.}
      \field{title}{Subgraph Matching Kernels for Attributed Graphs}
      \field{year}{2012}
      \verb{file}
      \verb :/home/fabrice/Documents/Uni/Literature/Papers/2012_Kriege_CONF.pdf:PDF
      \endverb
      \verb{urlraw}
      \verb https://arxiv.org/abs/1206.6483
      \endverb
      \verb{url}
      \verb https://arxiv.org/abs/1206.6483
      \endverb
      \keyw{graph matching,common subgraph,graph kernel,machine learning,ICML}
    \endentry
    \entry{2001_Helma_CONF}{article}{}
      \name{author}{4}{}{%
        {{hash=b4060685c6babec62cba9b947ff14351}{%
           family={Helma},
           familyi={H\bibinitperiod},
           given={C.},
           giveni={C\bibinitperiod}}}%
        {{hash=125623e7394dfa3fe23dd4490cf8d953}{%
           family={King},
           familyi={K\bibinitperiod},
           given={R.\bibnamedelimi D.},
           giveni={R\bibinitperiod\bibinitdelim D\bibinitperiod}}}%
        {{hash=ec05a5d3a4147ae1fcbf17d6f2510200}{%
           family={Kramer},
           familyi={K\bibinitperiod},
           given={S.},
           giveni={S\bibinitperiod}}}%
        {{hash=fb3796c076ecc8c5cff4d9274e1ff0bf}{%
           family={Srinivasan},
           familyi={S\bibinitperiod},
           given={A.},
           giveni={A\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Oxford University Press ({OUP})}%
      }
      \strng{namehash}{2ae28802b82250392a06c4665f0543d3}
      \strng{fullhash}{b22567986e1be73183e625b91cc54b57}
      \strng{bibnamehash}{2ae28802b82250392a06c4665f0543d3}
      \strng{authorbibnamehash}{2ae28802b82250392a06c4665f0543d3}
      \strng{authornamehash}{2ae28802b82250392a06c4665f0543d3}
      \strng{authorfullhash}{b22567986e1be73183e625b91cc54b57}
      \field{sortinit}{1}
      \field{sortinithash}{2174f786c6195e7fe2ee1c229b416e29}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{Bioinformatics}
      \field{month}{1}
      \field{number}{1}
      \field{title}{The Predictive Toxicology Challenge 2000-2001}
      \field{volume}{17}
      \field{year}{2001}
      \field{pages}{107\bibrangedash 108}
      \range{pages}{2}
      \verb{doi}
      \verb 10.1093/bioinformatics/17.1.107
      \endverb
    \endentry
    \entry{URL_TUDataset_Tox21}{online}{}
      \name{author}{1}{}{%
        {{hash=03196b586d791b967d56ea441a4ac67f}{%
           family={Advancing\bibnamedelimb Translational\bibnamedelima Sciences},
           familyi={A\bibinitperiod\bibinitdelim T\bibinitperiod\bibinitdelim S\bibinitperiod},
           given={National\bibnamedelima Cancer},
           giveni={N\bibinitperiod\bibinitdelim C\bibinitperiod},
           prefix={for},
           prefixi={f\bibinitperiod}}}%
      }
      \strng{namehash}{03196b586d791b967d56ea441a4ac67f}
      \strng{fullhash}{03196b586d791b967d56ea441a4ac67f}
      \strng{bibnamehash}{03196b586d791b967d56ea441a4ac67f}
      \strng{authorbibnamehash}{03196b586d791b967d56ea441a4ac67f}
      \strng{authornamehash}{03196b586d791b967d56ea441a4ac67f}
      \strng{authorfullhash}{03196b586d791b967d56ea441a4ac67f}
      \field{sortinit}{1}
      \field{sortinithash}{2174f786c6195e7fe2ee1c229b416e29}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{title}{Tox21 Data Challenge 2014}
      \field{urlday}{22}
      \field{urlmonth}{11}
      \field{urlyear}{2022}
      \field{year}{2022}
      \field{urldateera}{ce}
      \verb{urlraw}
      \verb https://tripod.nih.gov/tox21/challenge/data.jsp
      \endverb
      \verb{url}
      \verb https://tripod.nih.gov/tox21/challenge/data.jsp
      \endverb
    \endentry
    \entry{2015_Neumann_SPRINGER}{article}{}
      \name{author}{4}{}{%
        {{hash=1b772f8e40b5084f26030e1f86a6842a}{%
           family={Neumann},
           familyi={N\bibinitperiod},
           given={Marion},
           giveni={M\bibinitperiod}}}%
        {{hash=eaf84e3fe4f887967dc3d793d28b9e94}{%
           family={Garnett},
           familyi={G\bibinitperiod},
           given={Roman},
           giveni={R\bibinitperiod}}}%
        {{hash=a19299883183370e09a01f6cec3b9ea4}{%
           family={Bauckhage},
           familyi={B\bibinitperiod},
           given={Christian},
           giveni={C\bibinitperiod}}}%
        {{hash=231ca1992b128d48dbc73100fd196d87}{%
           family={Kersting},
           familyi={K\bibinitperiod},
           given={Kristian},
           giveni={K\bibinitperiod}}}%
      }
      \list{publisher}{2}{%
        {Springer Science}%
        {Business Media {LLC}}%
      }
      \strng{namehash}{55910464eee536726cab359990761ed9}
      \strng{fullhash}{9821e98b8dbbc51291597d7e522b80c8}
      \strng{bibnamehash}{55910464eee536726cab359990761ed9}
      \strng{authorbibnamehash}{55910464eee536726cab359990761ed9}
      \strng{authornamehash}{55910464eee536726cab359990761ed9}
      \strng{authorfullhash}{9821e98b8dbbc51291597d7e522b80c8}
      \field{sortinit}{1}
      \field{sortinithash}{2174f786c6195e7fe2ee1c229b416e29}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We introduce propagation kernels, a general graph-kernel framework for efficiently measuring the similarity of structured data. Propagation kernels are based on monitoring how information spreads through a set of given graphs. They leverage early-stage distributions from propagation schemes such as random walks to capture structural information encoded in node labels, attributes, and edge information. This has two benefits. First, off-the-shelf propagation schemes can be used to naturally construct kernels for many graph types, including labeled, partially labeled, unlabeled, directed, and attributed graphs. Second, by leveraging existing efficient and informative propagation schemes, propagation kernels can be considerably faster than state-of-the-art approaches without sacrificing predictive performance. We will also show that if the graphs at hand have a regular structure, for instance when modeling image or video data, one can exploit this regularity to scale the kernel computation to large databases of graphs with thousands of nodes. We support our contributions by exhaustive experiments on a number of real-world graphs from a variety of application domains.}
      \field{journaltitle}{Machine Learning}
      \field{month}{7}
      \field{number}{2}
      \field{title}{Propagation kernels: efficient graph kernels from propagated information}
      \field{volume}{102}
      \field{year}{2015}
      \field{pages}{209\bibrangedash 245}
      \range{pages}{37}
      \verb{doi}
      \verb 10.1007/s10994-015-5517-9
      \endverb
      \verb{urlraw}
      \verb https://link.springer.com/article/10.1007/s10994-015-5517-9
      \endverb
      \verb{url}
      \verb https://link.springer.com/article/10.1007/s10994-015-5517-9
      \endverb
    \endentry
    \entry{2018_Wu_CONF}{article}{}
      \name{author}{8}{}{%
        {{hash=1a7171075cce8a1996a27e5f1caa3626}{%
           family={Wu},
           familyi={W\bibinitperiod},
           given={Zhenqin},
           giveni={Z\bibinitperiod}}}%
        {{hash=6846cc99295752b57e920fdc36e377f2}{%
           family={Ramsundar},
           familyi={R\bibinitperiod},
           given={Bharath},
           giveni={B\bibinitperiod}}}%
        {{hash=99dce3d08074a30c38044650fb19a155}{%
           family={Feinberg},
           familyi={F\bibinitperiod},
           given={Evan\bibnamedelima N.},
           giveni={E\bibinitperiod\bibinitdelim N\bibinitperiod}}}%
        {{hash=84a58b20ec3d8ac61acd37d878d6b489}{%
           family={Gomes},
           familyi={G\bibinitperiod},
           given={Joseph},
           giveni={J\bibinitperiod}}}%
        {{hash=cb68944e84c3897f4d0f31e6acde09ca}{%
           family={Geniesse},
           familyi={G\bibinitperiod},
           given={Caleb},
           giveni={C\bibinitperiod}}}%
        {{hash=b8a51cd6bd68eb1abba959f570261639}{%
           family={Pappu},
           familyi={P\bibinitperiod},
           given={Aneesh\bibnamedelima S.},
           giveni={A\bibinitperiod\bibinitdelim S\bibinitperiod}}}%
        {{hash=48cd2bfc27ed0fa19df47e461793e26d}{%
           family={Leswing},
           familyi={L\bibinitperiod},
           given={Karl},
           giveni={K\bibinitperiod}}}%
        {{hash=8b199ddaf6c3a6930287f84fc29a82dd}{%
           family={Pande},
           familyi={P\bibinitperiod},
           given={Vijay},
           giveni={V\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Royal Society of Chemistry ({RSC})}%
      }
      \strng{namehash}{4d67fa8081bb2c7b164b0bee3f818d4b}
      \strng{fullhash}{0a2fef0ee879537d14736b9a644eacaf}
      \strng{bibnamehash}{4d67fa8081bb2c7b164b0bee3f818d4b}
      \strng{authorbibnamehash}{4d67fa8081bb2c7b164b0bee3f818d4b}
      \strng{authornamehash}{4d67fa8081bb2c7b164b0bee3f818d4b}
      \strng{authorfullhash}{0a2fef0ee879537d14736b9a644eacaf}
      \field{sortinit}{1}
      \field{sortinithash}{2174f786c6195e7fe2ee1c229b416e29}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Molecular machine learning has been maturing rapidly over the last few years. Improved methods and the presence of larger datasets have enabled machine learning algorithms to make increasingly accurate predictions about molecular properties. However, algorithmic progress has been limited due to the lack of a standard benchmark to compare the efficacy of proposed methods; most new algorithms are benchmarked on different datasets making it challenging to gauge the quality of proposed methods. This work introduces MoleculeNet, a large scale benchmark for molecular machine learning. MoleculeNet curates multiple public datasets, establishes metrics for evaluation, and offers high quality open-source implementations of multiple previously proposed molecular featurization and learning algorithms (released as part of the DeepChem open source library). MoleculeNet benchmarks demonstrate that learnable representations are powerful tools for molecular machine learning and broadly offer the best performance. However, this result comes with caveats. Learnable representations still struggle to deal with complex tasks under data scarcity and highly imbalanced classification. For quantum mechanical and biophysical datasets, the use of physics-aware featurizations can be more important than choice of particular learning algorithm.}
      \field{journaltitle}{Chemical Science}
      \field{number}{2}
      \field{title}{{MoleculeNet}: a benchmark for molecular machine learning}
      \field{volume}{9}
      \field{year}{2018}
      \field{pages}{513\bibrangedash 530}
      \range{pages}{18}
      \verb{doi}
      \verb 10.1039/c7sc02664a
      \endverb
    \endentry
  \enddatalist
\endrefsection
\endinput

